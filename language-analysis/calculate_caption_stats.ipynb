{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the likelihood of winoground captions using RoBERTa base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess the winoground dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.25.1)\n",
      "Requirement already satisfied: fsspec in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2022.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: datasets in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (2.13.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: aiohttp in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.25.1)\n",
      "Requirement already satisfied: packaging in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pandas in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: filelock in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.12)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/simrankhanuja/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset winoground (/Users/simrankhanuja/.cache/huggingface/datasets/facebook___winoground/default/0.0.0/72585f4d9cd5a28790bb9bc2adbdd45633f36dfbf85df529e0756e114e134285)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5490b1ed7b4b45b9f179451cecebe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "auth_token = \"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\"  # Replace with an auth token, which you can get from your huggingface account: Profile -> Settings -> Access Tokens -> New Token\n",
    "winoground = load_dataset(\"facebook/winoground\", use_auth_token=auth_token)[\"test\"]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize\n",
    "    transforms.ToTensor()           # Convert to PyTorch tensor\n",
    "])\n",
    "\n",
    "def transform_wino(examples):\n",
    "    examples[\"image_0\"] = [transform(image.convert(\"RGB\")) for image in examples[\"image_0\"]]\n",
    "    examples[\"image_1\"] = [transform(image.convert(\"RGB\")) for image in examples[\"image_1\"]]\n",
    "    return examples\n",
    "\n",
    "winoground.set_transform(transform_wino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate log likelihood of captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Two lists of sentences\n",
    "captions0 = []\n",
    "captions1 = []\n",
    "\n",
    "for sample in winoground:\n",
    "    captions0.append(sample[\"caption_0\"])\n",
    "    captions1.append(sample[\"caption_1\"])\n",
    "\n",
    "# Compute embedding for both lists\n",
    "embeddings1 = model.encode(captions0, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(captions1, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine-similarities\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "sentence_similarity = {}\n",
    "count = 0\n",
    "# Output the pairs with their score\n",
    "for i in range(len(captions0)):\n",
    "    sentence_similarity[count] = float(cosine_scores[i][i].numpy())\n",
    "    count += 1\n",
    "    sentence_similarity[count] = float(cosine_scores[i][i].numpy())\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentence_trans_sim.json\", 'w') as f:\n",
    "  json.dump(sentence_similarity, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vitb8 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9989266395568848\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTModel\n",
    "import torch.nn.functional as F\n",
    " \n",
    "processor = ViTImageProcessor.from_pretrained('facebook/dino-vitb8')\n",
    "model = ViTModel.from_pretrained('facebook/dino-vitb8').eval()\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "cosine_similarities = []\n",
    "for i in range(0, len(winoground), batch_size):\n",
    "    end_idx = i+batch_size if i+batch_size < len(winoground) else len(winoground)\n",
    "    cap0_batch = winoground[i:end_idx][\"image_0\"]\n",
    "    cap1_batch = winoground[i:end_idx][\"image_1\"]\n",
    "    cap0_inputs = processor(cap0_batch, return_tensors=\"pt\", padding=True)\n",
    "    cap1_inputs = processor(cap1_batch, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    cap0_features = model(**cap0_inputs).last_hidden_state.mean(dim=1)\n",
    "    cap1_features = model(**cap1_inputs).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    cap0_features = torch.nn.functional.normalize(cap0_features, p=2, dim=1)\n",
    "    cap1_features = torch.nn.functional.normalize(cap1_features, p=2, dim=1)\n",
    "\n",
    "    cosine_similarities.extend(F.cosine_similarity(cap0_features, cap1_features).cpu().tolist())\n",
    "    print(cosine_similarities[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "import json\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"roberta-base\"\n",
    "model = RobertaForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "def calculate_log_likelihood(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        log_likelihood = outputs.logits.gather(2, inputs[\"input_ids\"].unsqueeze(-1)).sum().item()\n",
    "    return log_likelihood\n",
    "  \n",
    "\n",
    "likelihood = {}  # To store max softmax probabilities for all images\n",
    "count = 0\n",
    "for sample in winoground:\n",
    "    cap_0 = sample[\"caption_0\"]\n",
    "    cap_1 = sample[\"caption_1\"]\n",
    "\n",
    "    ll_cap_0 = calculate_log_likelihood(cap_0) / len(tokenizer.tokenize(cap_0))\n",
    "    ll_cap_1 = calculate_log_likelihood(cap_1) / len(tokenizer.tokenize(cap_1))\n",
    "\n",
    "    likelihood[count] = ll_cap_0\n",
    "    count+=1\n",
    "    likelihood[count] = ll_cap_1\n",
    "    count+=1\n",
    "\n",
    "text_likelihood = {}\n",
    "for i in likelihood:\n",
    "  text_likelihood[i] = str(f'{likelihood[i]:.3f}')\n",
    "\n",
    "with open(\"text_likelihood.json\", 'w') as f:\n",
    "  json.dump(text_likelihood, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
