{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.13.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Using cached huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-1.26.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2023.10.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
      "  Using cached tokenizers-0.14.1-cp310-cp310-macosx_10_7_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Using cached safetensors-0.4.0-cp310-cp310-macosx_10_7_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->transformers)\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.16.4->transformers)\n",
      "  Using cached typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Using cached huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.3.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
      "Using cached numpy-1.26.1-cp310-cp310-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Using cached PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl (189 kB)\n",
      "Using cached regex-2023.10.3-cp310-cp310-macosx_10_9_x86_64.whl (296 kB)\n",
      "Using cached safetensors-0.4.0-cp310-cp310-macosx_10_7_x86_64.whl (439 kB)\n",
      "Using cached tokenizers-0.14.1-cp310-cp310-macosx_10_7_x86_64.whl (2.5 MB)\n",
      "Using cached huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.13.0-py3-none-any.whl (11 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "Using cached charset_normalizer-3.3.1-cp310-cp310-macosx_10_9_x86_64.whl (120 kB)\n",
      "Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Using cached urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2023.7.22 charset-normalizer-3.3.1 filelock-3.13.0 fsspec-2023.10.0 huggingface-hub-0.17.3 idna-3.4 numpy-1.26.1 pyyaml-6.0.1 regex-2023.10.3 requests-2.31.0 safetensors-0.4.0 tokenizers-0.14.1 tqdm-4.66.1 transformers-4.34.1 typing-extensions-4.8.0 urllib3-2.0.7\n",
      "Collecting datasets\n",
      "  Using cached datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from datasets) (1.26.1)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Using cached pyarrow-13.0.0-cp310-cp310-macosx_10_14_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.1.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.4.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Using cached multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.8.6-cp310-cp310-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from aiohttp->datasets) (3.3.1)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.0.4-cp310-cp310-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.9.2-cp310-cp310-macosx_10_9_x86_64.whl (65 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.4.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: filelock in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas->datasets)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-2.14.6-py3-none-any.whl (493 kB)\n",
      "Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Using cached aiohttp-3.8.6-cp310-cp310-macosx_10_9_x86_64.whl (368 kB)\n",
      "Using cached pyarrow-13.0.0-cp310-cp310-macosx_10_14_x86_64.whl (25.9 MB)\n",
      "Using cached multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "Downloading pandas-2.1.2-cp310-cp310-macosx_10_9_x86_64.whl (11.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached xxhash-3.4.1-cp310-cp310-macosx_10_9_x86_64.whl (31 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached frozenlist-1.4.0-cp310-cp310-macosx_10_9_x86_64.whl (46 kB)\n",
      "Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, multidict, frozenlist, dill, attrs, async-timeout, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 datasets-2.14.6 dill-0.3.7 frozenlist-1.4.0 multidict-6.0.4 multiprocess-0.70.15 pandas-2.1.2 pyarrow-13.0.0 pytz-2023.3.post1 tzdata-2023.3 xxhash-3.4.1 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages/datasets/load.py:2089: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=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' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "auth_token = \"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\"  # Replace with an auth token, which you can get from your huggingface account: Profile -> Settings -> Access Tokens -> New Token\n",
    "winoground = load_dataset(\"facebook/winoground\", use_auth_token=auth_token)[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Using cached torchvision-0.16.0-cp310-cp310-macosx_10_13_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: requests in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Collecting torch==2.1.0 (from torchvision)\n",
      "  Using cached torch-2.1.0-cp310-none-macosx_10_9_x86_64.whl.metadata (24 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached Pillow-10.1.0-cp310-cp310-macosx_10_10_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: filelock in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from torch==2.1.0->torchvision) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from torch==2.1.0->torchvision) (4.8.0)\n",
      "Collecting sympy (from torch==2.1.0->torchvision)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch==2.1.0->torchvision)\n",
      "  Using cached networkx-3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch==2.1.0->torchvision)\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: fsspec in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from torch==2.1.0->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from requests->torchvision) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.0->torchvision)\n",
      "  Using cached MarkupSafe-2.1.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch==2.1.0->torchvision)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached torchvision-0.16.0-cp310-cp310-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "Using cached torch-2.1.0-cp310-none-macosx_10_9_x86_64.whl (147.0 MB)\n",
      "Using cached Pillow-10.1.0-cp310-cp310-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "Using cached networkx-3.2-py3-none-any.whl (1.6 MB)\n",
      "Using cached MarkupSafe-2.1.3-cp310-cp310-macosx_10_9_x86_64.whl (13 kB)\n",
      "Installing collected packages: mpmath, sympy, pillow, networkx, MarkupSafe, jinja2, torch, torchvision\n",
      "Successfully installed MarkupSafe-2.1.3 jinja2-3.1.2 mpmath-1.3.0 networkx-3.2 pillow-10.1.0 sympy-1.12 torch-2.1.0 torchvision-0.16.0\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.0-cp310-cp310-macosx_10_12_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.1.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.43.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (152 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from matplotlib) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from matplotlib) (10.1.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.8.0-cp310-cp310-macosx_10_12_x86_64.whl (7.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.1.1-cp310-cp310-macosx_10_9_x86_64.whl (247 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.2/247.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.43.1-cp310-cp310-macosx_10_9_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-macosx_10_9_x86_64.whl (68 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.43.1 kiwisolver-1.4.5 matplotlib-3.8.0 pyparsing-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow==8.2\n",
      "  Downloading Pillow-8.2.0.tar.gz (47.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 MB\u001b[0m \u001b[31m957.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: Pillow\n",
      "  Building wheel for Pillow (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Pillow: filename=Pillow-8.2.0-cp310-cp310-macosx_10_9_x86_64.whl size=524429 sha256=dc24478922853c255c49255ceb9324ebaa729290390c381b3717e6549cc1fb5b\n",
      "  Stored in directory: /Users/simrankhanuja/Library/Caches/pip/wheels/70/8a/2c/7f8208f565545ea014c5644ed58e3dece5a462b98fe8d6d148\n",
      "Successfully built Pillow\n",
      "Installing collected packages: Pillow\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 10.1.0\n",
      "    Uninstalling Pillow-10.1.0:\n",
      "      Successfully uninstalled Pillow-10.1.0\n",
      "Successfully installed Pillow-8.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow==8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(ind, caption=True):\n",
    "\n",
    "  image_0 = winoground[ind][\"image_0\"].convert(\"RGB\")\n",
    "  image_1 = winoground[ind][\"image_1\"].convert(\"RGB\")\n",
    "  cap_0 = winoground[ind][\"caption_0\"]\n",
    "  cap_1 = winoground[ind][\"caption_1\"]\n",
    "\n",
    "  print(f\"Sample ID: {ind}\")\n",
    "  print(\"#################\")\n",
    "  plt.figure(figsize=(9,7))\n",
    "  ax1 = plt.subplot(1,2,1)\n",
    "  if caption:\n",
    "    ax1.title.set_text(f\"{cap_0}\")\n",
    "  plt.imshow(image_0)\n",
    "  plt.axis(\"off\")\n",
    "  plt.tight_layout()\n",
    "\n",
    "  ax2 = plt.subplot(1,2,2)\n",
    "  if caption:\n",
    "    ax2.title.set_text(f\"{cap_1}\")\n",
    "  plt.imshow(image_1)\n",
    "  plt.axis(\"off\")\n",
    "  plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize\n",
    "    transforms.ToTensor()           # Convert to PyTorch tensor\n",
    "])\n",
    "\n",
    "def transform_wino(examples):\n",
    "    examples[\"image_0\"] = [transform(image.convert(\"RGB\")) for image in examples[\"image_0\"]]\n",
    "    examples[\"image_1\"] = [transform(image.convert(\"RGB\")) for image in examples[\"image_1\"]]\n",
    "    return examples\n",
    "\n",
    "winoground.set_transform(transform_wino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.3.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/simrankhanuja/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages (from scikit-learn) (1.26.1)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Using cached scipy-1.11.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Using cached scikit_learn-1.3.2-cp310-cp310-macosx_10_9_x86_64.whl (10.2 MB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached scipy-1.11.3-cp310-cp310-macosx_10_9_x86_64.whl (37.3 MB)\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 scipy-1.11.3 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading model.safetensors: 100%|██████████| 4.55G/4.55G [03:04<00:00, 24.7MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/simrankhanuja/Desktop/11777-project/unimodal_evaluation/roberta_vit.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simrankhanuja/Desktop/11777-project/unimodal_evaluation/roberta_vit.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Load Vision Transformer model and feature extractor\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simrankhanuja/Desktop/11777-project/unimodal_evaluation/roberta_vit.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# vit_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k', output_hidden_states=True).eval()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simrankhanuja/Desktop/11777-project/unimodal_evaluation/roberta_vit.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# vit_feature_extractor = ViTFeatureExtractor()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simrankhanuja/Desktop/11777-project/unimodal_evaluation/roberta_vit.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m processor \u001b[39m=\u001b[39m AutoImageProcessor\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mfacebook/dinov2-giant\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/simrankhanuja/Desktop/11777-project/unimodal_evaluation/roberta_vit.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m'\u001b[39;49m\u001b[39mfacebook/dinov2-giant\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simrankhanuja/Desktop/11777-project/unimodal_evaluation/roberta_vit.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_text_embedding\u001b[39m(text, model, tokenizer):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simrankhanuja/Desktop/11777-project/unimodal_evaluation/roberta_vit.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     inputs \u001b[39m=\u001b[39m tokenizer(text, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_length\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:565\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    564\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 565\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    566\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    569\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages/transformers/modeling_utils.py:3307\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3297\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3298\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3300\u001b[0m     (\n\u001b[1;32m   3301\u001b[0m         model,\n\u001b[1;32m   3302\u001b[0m         missing_keys,\n\u001b[1;32m   3303\u001b[0m         unexpected_keys,\n\u001b[1;32m   3304\u001b[0m         mismatched_keys,\n\u001b[1;32m   3305\u001b[0m         offload_index,\n\u001b[1;32m   3306\u001b[0m         error_msgs,\n\u001b[0;32m-> 3307\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[1;32m   3308\u001b[0m         model,\n\u001b[1;32m   3309\u001b[0m         state_dict,\n\u001b[1;32m   3310\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3311\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3312\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3313\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[1;32m   3314\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[1;32m   3315\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[1;32m   3316\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[1;32m   3317\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   3318\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   3319\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m   3320\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m   3321\u001b[0m         is_quantized\u001b[39m=\u001b[39;49m(\u001b[39mgetattr\u001b[39;49m(model, \u001b[39m\"\u001b[39;49m\u001b[39mquantization_method\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m) \u001b[39m==\u001b[39;49m QuantizationMethod\u001b[39m.\u001b[39;49mBITS_AND_BYTES),\n\u001b[1;32m   3322\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[1;32m   3323\u001b[0m     )\n\u001b[1;32m   3325\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_4bit \u001b[39m=\u001b[39m load_in_4bit\n\u001b[1;32m   3326\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_8bit \u001b[39m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages/transformers/modeling_utils.py:3649\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3639\u001b[0m \u001b[39mif\u001b[39;00m state_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3640\u001b[0m     \u001b[39m# Whole checkpoint\u001b[39;00m\n\u001b[1;32m   3641\u001b[0m     mismatched_keys \u001b[39m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3642\u001b[0m         state_dict,\n\u001b[1;32m   3643\u001b[0m         model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3647\u001b[0m         ignore_mismatched_sizes,\n\u001b[1;32m   3648\u001b[0m     )\n\u001b[0;32m-> 3649\u001b[0m     error_msgs \u001b[39m=\u001b[39m _load_state_dict_into_model(model_to_load, state_dict, start_prefix)\n\u001b[1;32m   3650\u001b[0m     offload_index \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3651\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3652\u001b[0m     \u001b[39m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n\u001b[1;32m   3653\u001b[0m \n\u001b[1;32m   3654\u001b[0m     \u001b[39m# This should always be a list but, just to be sure.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages/transformers/modeling_utils.py:571\u001b[0m, in \u001b[0;36m_load_state_dict_into_model\u001b[0;34m(model_to_load, state_dict, start_prefix)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[39mif\u001b[39;00m child \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m             load(child, state_dict, prefix \u001b[39m+\u001b[39m name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 571\u001b[0m load(model_to_load, state_dict, prefix\u001b[39m=\u001b[39;49mstart_prefix)\n\u001b[1;32m    572\u001b[0m \u001b[39m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39m# it's safe to delete it.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39mdel\u001b[39;00m state_dict\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages/transformers/modeling_utils.py:569\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m child \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 569\u001b[0m         load(child, state_dict, prefix \u001b[39m+\u001b[39;49m name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages/transformers/modeling_utils.py:569\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m child \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 569\u001b[0m         load(child, state_dict, prefix \u001b[39m+\u001b[39;49m name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "    \u001b[0;31m[... skipping similar frames: _load_state_dict_into_model.<locals>.load at line 569 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages/transformers/modeling_utils.py:569\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m child \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 569\u001b[0m         load(child, state_dict, prefix \u001b[39m+\u001b[39;49m name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages/transformers/modeling_utils.py:565\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    563\u001b[0m                     module\u001b[39m.\u001b[39m_load_from_state_dict(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m         module\u001b[39m.\u001b[39;49m_load_from_state_dict(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    567\u001b[0m \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m child \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/trial-env-py10/lib/python3.10/site-packages/torch/nn/modules/module.py:2040\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                 \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m, name, input_param)\n\u001b[1;32m   2039\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2040\u001b[0m             param\u001b[39m.\u001b[39;49mcopy_(input_param)\n\u001b[1;32m   2041\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m   2042\u001b[0m     error_msgs\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mWhile copying the parameter named \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2043\u001b[0m                       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwhose dimensions in the model are \u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2044\u001b[0m                       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwhose dimensions in the checkpoint are \u001b[39m\u001b[39m{\u001b[39;00minput_param\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2045\u001b[0m                       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39man exception occurred : \u001b[39m\u001b[39m{\u001b[39;00mex\u001b[39m.\u001b[39margs\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2046\u001b[0m                       )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from transformers import RobertaTokenizer, RobertaModel, ViTFeatureExtractor, ViTModel\n",
    "from transformers import AutoModel, AutoTokenizer, AutoImageProcessor, Dinov2Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "\n",
    "# Load RoBERTa model and tokenizer\n",
    "roberta_model = AutoModel.from_pretrained('roberta-large', output_hidden_states=True).eval()\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained('roberta-large')\n",
    "\n",
    "# Load Vision Transformer model and feature extractor\n",
    "# vit_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k', output_hidden_states=True).eval()\n",
    "# vit_feature_extractor = ViTFeatureExtractor()\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-giant')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-giant')\n",
    "\n",
    "def get_text_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1)  # mean pooling\n",
    "    #     layers_4_8 = torch.stack(outputs.hidden_states[4:9]).mean(0)\n",
    "    # return layers_4_8.mean(dim=1)  # mean pooling across tokens\n",
    "\n",
    "def get_image_embedding(image, model, feature_extractor):\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # return outputs.last_hidden_state[:,0,:]  # Taking the [CLS] token representation\n",
    "    return outputs.last_hidden_state.mean(dim=1)\n",
    "    # layers_4_8 = torch.stack(outputs.hidden_states[4:9]).mean(0)\n",
    "    # return layers_4_8.mean(dim=1)  # mean pooling across tokens\n",
    "\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    return cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "# Embedding normalization function\n",
    "def normalize_embedding(embedding):\n",
    "    return embedding / torch.norm(embedding, dim=1, keepdim=True)\n",
    "\n",
    "def text_correct(result):\n",
    "    return result[\"c0_i0\"] > result[\"c1_i0\"] and result[\"c1_i1\"] > result[\"c0_i1\"]\n",
    "\n",
    "def image_correct(result):\n",
    "    return result[\"c0_i0\"] > result[\"c0_i1\"] and result[\"c1_i1\"] > result[\"c1_i0\"]\n",
    "\n",
    "def group_correct(result):\n",
    "    return image_correct(result) and text_correct(result)\n",
    "\n",
    "\n",
    "winoground_scores = {}\n",
    "\n",
    "# Extracting embeddings and computing similarities\n",
    "for ind in range(len(winoground)):\n",
    "    # Get embeddings\n",
    "    text_embedding_0 = normalize_embedding(get_text_embedding(winoground[ind][\"caption_0\"], roberta_model, roberta_tokenizer))\n",
    "    text_embedding_1 = normalize_embedding(get_text_embedding(winoground[ind][\"caption_1\"], roberta_model, roberta_tokenizer))\n",
    "    image_embedding_0 = normalize_embedding(get_image_embedding([winoground[ind][\"image_0\"]], model, processor))\n",
    "    image_embedding_1 = normalize_embedding(get_image_embedding([winoground[ind][\"image_1\"]], model, processor))\n",
    "    \n",
    "    # Compute similarities\n",
    "    winoground_scores[ind] = {\n",
    "        \"c0_i0\": compute_similarity(text_embedding_0, image_embedding_0)[0][0],\n",
    "        \"c0_i1\": compute_similarity(text_embedding_0, image_embedding_1)[0][0],\n",
    "        \"c1_i0\": compute_similarity(text_embedding_1, image_embedding_0)[0][0],\n",
    "        \"c1_i1\": compute_similarity(text_embedding_1, image_embedding_1)[0][0],\n",
    "        \"i0_i1\": compute_similarity(image_embedding_0, image_embedding_1)[0][0],\n",
    "        \"c0_c1\": compute_similarity(text_embedding_0, text_embedding_1)[0][0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'c0_i0': -0.019976094, 'c0_i1': -0.020162042, 'c1_i0': -0.020759415, 'c1_i1': -0.020863557, 'i0_i1': 0.9996182, 'c0_c1': 0.9993835}, 1: {'c0_i0': -0.012033173, 'c0_i1': -0.012521299, 'c1_i0': -0.012088006, 'c1_i1': -0.012576947, 'i0_i1': 0.9998855, 'c0_c1': 0.9997037}, 2: {'c0_i0': -0.019636407, 'c0_i1': -0.018449932, 'c1_i0': -0.022360153, 'c1_i1': -0.021095332, 'i0_i1': 0.999434, 'c0_c1': 0.9991006}, 3: {'c0_i0': -0.009377154, 'c0_i1': -0.0098777935, 'c1_i0': -0.005103141, 'c1_i1': -0.0056237737, 'i0_i1': 0.9999176, 'c0_c1': 0.9974456}, 4: {'c0_i0': -0.0033664517, 'c0_i1': -0.0032716384, 'c1_i0': -0.0016864426, 'c1_i1': -0.001601439, 'i0_i1': 0.9999733, 'c0_c1': 0.99936527}, 5: {'c0_i0': -0.014464635, 'c0_i1': -0.014493011, 'c1_i0': -0.014349988, 'c1_i1': -0.014378224, 'i0_i1': 0.99995536, 'c0_c1': 0.9994589}, 6: {'c0_i0': -0.012075642, 'c0_i1': -0.012018301, 'c1_i0': -0.009999774, 'c1_i1': -0.009942228, 'i0_i1': 0.9998328, 'c0_c1': 0.99904585}, 7: {'c0_i0': -0.011815451, 'c0_i1': -0.011820904, 'c1_i0': -0.018151067, 'c1_i1': -0.018145457, 'i0_i1': 0.9998634, 'c0_c1': 0.99061584}, 8: {'c0_i0': -0.036547095, 'c0_i1': -0.036681388, 'c1_i0': -0.037262194, 'c1_i1': -0.03734798, 'i0_i1': 0.99991643, 'c0_c1': 0.9986741}, 9: {'c0_i0': -0.021676308, 'c0_i1': -0.022175279, 'c1_i0': -0.013857294, 'c1_i1': -0.01437448, 'i0_i1': 0.9998977, 'c0_c1': 0.99305856}, 10: {'c0_i0': -0.017491508, 'c0_i1': -0.017390445, 'c1_i0': -0.016460063, 'c1_i1': -0.016364051, 'i0_i1': 0.9999518, 'c0_c1': 0.9975687}, 11: {'c0_i0': -0.017247567, 'c0_i1': -0.016999116, 'c1_i0': -0.024507936, 'c1_i1': -0.024284743, 'i0_i1': 0.9998113, 'c0_c1': 0.99165577}, 12: {'c0_i0': -0.01715292, 'c0_i1': -0.017291533, 'c1_i0': -0.016150527, 'c1_i1': -0.016268373, 'i0_i1': 0.9999436, 'c0_c1': 0.9983904}, 13: {'c0_i0': -0.011108129, 'c0_i1': -0.010615086, 'c1_i0': -0.007079363, 'c1_i1': -0.0065803844, 'i0_i1': 0.9998681, 'c0_c1': 0.9931476}, 14: {'c0_i0': -0.016776096, 'c0_i1': -0.016770372, 'c1_i0': -0.013908697, 'c1_i1': -0.0138955945, 'i0_i1': 0.9999038, 'c0_c1': 0.9958813}, 15: {'c0_i0': -0.005987416, 'c0_i1': -0.0049178274, 'c1_i0': -0.005970603, 'c1_i1': -0.004870153, 'i0_i1': 0.999822, 'c0_c1': 0.99964875}, 16: {'c0_i0': -0.0006906241, 'c0_i1': -0.00041253865, 'c1_i0': -0.0013246965, 'c1_i1': -0.0010549203, 'i0_i1': 0.9999238, 'c0_c1': 0.99926627}, 17: {'c0_i0': -0.0032650642, 'c0_i1': -0.0024318509, 'c1_i0': -0.0045012645, 'c1_i1': -0.0037289727, 'i0_i1': 0.99981385, 'c0_c1': 0.9991485}, 18: {'c0_i0': -0.009924307, 'c0_i1': -0.0103843855, 'c1_i0': -0.010371473, 'c1_i1': -0.010814104, 'i0_i1': 0.99991083, 'c0_c1': 0.99942416}, 19: {'c0_i0': -0.012030821, 'c0_i1': -0.0117744785, 'c1_i0': -0.012611175, 'c1_i1': -0.012334653, 'i0_i1': 0.9998108, 'c0_c1': 0.99939454}, 20: {'c0_i0': -0.0031906422, 'c0_i1': -0.0028075306, 'c1_i0': -0.002882231, 'c1_i1': -0.002494106, 'i0_i1': 0.99995506, 'c0_c1': 0.9997637}, 21: {'c0_i0': -0.0059784604, 'c0_i1': -0.0064954646, 'c1_i0': -0.0068882126, 'c1_i1': -0.00741187, 'i0_i1': 0.99991286, 'c0_c1': 0.99946207}, 22: {'c0_i0': -0.0049545495, 'c0_i1': -0.004548208, 'c1_i0': -0.0051562116, 'c1_i1': -0.0047489386, 'i0_i1': 0.9999545, 'c0_c1': 0.9996965}, 23: {'c0_i0': -0.011427396, 'c0_i1': -0.01134419, 'c1_i0': -0.011525474, 'c1_i1': -0.011444684, 'i0_i1': 0.99997866, 'c0_c1': 0.99975514}, 24: {'c0_i0': -0.014867594, 'c0_i1': -0.0146420775, 'c1_i0': -0.014104482, 'c1_i1': -0.013898319, 'i0_i1': 0.9997941, 'c0_c1': 0.9995989}, 25: {'c0_i0': -0.01599944, 'c0_i1': -0.016017396, 'c1_i0': -0.015958974, 'c1_i1': -0.016021483, 'i0_i1': 0.999764, 'c0_c1': 0.9991412}, 26: {'c0_i0': -0.007401867, 'c0_i1': -0.007955179, 'c1_i0': -0.0070280563, 'c1_i1': -0.0075859465, 'i0_i1': 0.9998957, 'c0_c1': 0.9997105}, 27: {'c0_i0': -0.018134154, 'c0_i1': -0.01721594, 'c1_i0': -0.01915329, 'c1_i1': -0.018278921, 'i0_i1': 0.9995652, 'c0_c1': 0.9993154}, 28: {'c0_i0': -0.006817965, 'c0_i1': -0.0066761486, 'c1_i0': -0.007118213, 'c1_i1': -0.006976923, 'i0_i1': 0.99997413, 'c0_c1': 0.99994}, 29: {'c0_i0': -0.020898415, 'c0_i1': -0.020382153, 'c1_i0': -0.021019934, 'c1_i1': -0.020511286, 'i0_i1': 0.9998176, 'c0_c1': 0.99978083}, 30: {'c0_i0': -0.013323209, 'c0_i1': -0.0134646455, 'c1_i0': -0.01330851, 'c1_i1': -0.013449574, 'i0_i1': 0.9998486, 'c0_c1': 0.999921}, 31: {'c0_i0': -0.0016753441, 'c0_i1': -0.001607365, 'c1_i0': -0.0012478493, 'c1_i1': -0.0011809757, 'i0_i1': 0.999936, 'c0_c1': 0.99993277}, 32: {'c0_i0': -0.0069561237, 'c0_i1': -0.006606074, 'c1_i0': -0.0065751085, 'c1_i1': -0.0062160017, 'i0_i1': 0.9999462, 'c0_c1': 0.9998985}, 33: {'c0_i0': -0.0028700987, 'c0_i1': -0.002583948, 'c1_i0': -0.0056741126, 'c1_i1': -0.005418438, 'i0_i1': 0.9997937, 'c0_c1': 0.9989944}, 34: {'c0_i0': -0.017974522, 'c0_i1': -0.017885344, 'c1_i0': -0.011915565, 'c1_i1': -0.011852689, 'i0_i1': 0.9999092, 'c0_c1': 0.99274516}, 35: {'c0_i0': -0.00069106556, 'c0_i1': -0.00088486355, 'c1_i0': -0.00084270816, 'c1_i1': -0.0010290509, 'i0_i1': 0.99997187, 'c0_c1': 0.9998274}, 36: {'c0_i0': -0.017759306, 'c0_i1': -0.017402997, 'c1_i0': -0.01857458, 'c1_i1': -0.018210186, 'i0_i1': 0.99984455, 'c0_c1': 0.9996966}, 37: {'c0_i0': -0.010955811, 'c0_i1': -0.010614473, 'c1_i0': -0.011922931, 'c1_i1': -0.011709692, 'i0_i1': 0.99969494, 'c0_c1': 0.99588364}, 38: {'c0_i0': -0.009169554, 'c0_i1': -0.009272365, 'c1_i0': -0.008301477, 'c1_i1': -0.008405862, 'i0_i1': 0.9995978, 'c0_c1': 0.9998296}, 39: {'c0_i0': -0.011174581, 'c0_i1': -0.011251238, 'c1_i0': -0.011445858, 'c1_i1': -0.011488298, 'i0_i1': 0.9996784, 'c0_c1': 0.9996965}, 40: {'c0_i0': -0.0052088154, 'c0_i1': -0.0043963008, 'c1_i0': -0.005708942, 'c1_i1': -0.0049147103, 'i0_i1': 0.99972856, 'c0_c1': 0.9997902}, 41: {'c0_i0': -0.0022691982, 'c0_i1': -0.0018874286, 'c1_i0': -0.0027477099, 'c1_i1': -0.0023606736, 'i0_i1': 0.99984765, 'c0_c1': 0.9997926}, 42: {'c0_i0': -0.0054331077, 'c0_i1': -0.005109936, 'c1_i0': -0.0056281453, 'c1_i1': -0.0053120106, 'i0_i1': 0.99985117, 'c0_c1': 0.9999252}, 43: {'c0_i0': -0.02381225, 'c0_i1': -0.024004662, 'c1_i0': -0.022789115, 'c1_i1': -0.022969255, 'i0_i1': 0.99990284, 'c0_c1': 0.9996743}, 44: {'c0_i0': -0.013134323, 'c0_i1': -0.012677865, 'c1_i0': -0.012025479, 'c1_i1': -0.0116103515, 'i0_i1': 0.99971116, 'c0_c1': 0.999494}, 45: {'c0_i0': -0.012954012, 'c0_i1': -0.013594318, 'c1_i0': -0.013816387, 'c1_i1': -0.014529572, 'i0_i1': 0.99940145, 'c0_c1': 0.9994156}, 46: {'c0_i0': -0.012188699, 'c0_i1': -0.012633571, 'c1_i0': -0.013479207, 'c1_i1': -0.013936808, 'i0_i1': 0.99991214, 'c0_c1': 0.9990601}, 47: {'c0_i0': -0.01874714, 'c0_i1': -0.017833333, 'c1_i0': -0.019638548, 'c1_i1': -0.018684082, 'i0_i1': 0.9999221, 'c0_c1': 0.9989162}, 48: {'c0_i0': -0.013496728, 'c0_i1': -0.014541714, 'c1_i0': -0.013658255, 'c1_i1': -0.0146929175, 'i0_i1': 0.9996073, 'c0_c1': 0.9991624}, 49: {'c0_i0': -0.009669014, 'c0_i1': -0.00913462, 'c1_i0': -0.014201379, 'c1_i1': -0.013548359, 'i0_i1': 0.9997307, 'c0_c1': 0.99800533}, 50: {'c0_i0': 0.0018643383, 'c0_i1': 0.0016343761, 'c1_i0': 0.00085772946, 'c1_i1': 0.0006337287, 'i0_i1': 0.99995816, 'c0_c1': 0.99974036}, 51: {'c0_i0': -0.024346163, 'c0_i1': -0.024307368, 'c1_i0': -0.022470353, 'c1_i1': -0.02243912, 'i0_i1': 0.99989086, 'c0_c1': 0.99877703}, 52: {'c0_i0': -0.017809546, 'c0_i1': -0.01777212, 'c1_i0': -0.015811026, 'c1_i1': -0.015771145, 'i0_i1': 0.99995655, 'c0_c1': 0.9991841}, 53: {'c0_i0': -0.020416372, 'c0_i1': -0.020200804, 'c1_i0': -0.019078027, 'c1_i1': -0.018950831, 'i0_i1': 0.99953014, 'c0_c1': 0.9987398}, 54: {'c0_i0': -0.034917787, 'c0_i1': -0.03474544, 'c1_i0': -0.036044955, 'c1_i1': -0.0358261, 'i0_i1': 0.9997558, 'c0_c1': 0.99881554}, 55: {'c0_i0': -0.007190689, 'c0_i1': -0.007291726, 'c1_i0': -0.0072072847, 'c1_i1': -0.007306042, 'i0_i1': 0.9999445, 'c0_c1': 0.9999722}, 56: {'c0_i0': -0.02510491, 'c0_i1': -0.024110558, 'c1_i0': -0.026294902, 'c1_i1': -0.025298774, 'i0_i1': 0.9994683, 'c0_c1': 0.99893916}, 57: {'c0_i0': -0.00728371, 'c0_i1': -0.006658093, 'c1_i0': -0.009950604, 'c1_i1': -0.009351848, 'i0_i1': 0.99993086, 'c0_c1': 0.9981637}, 58: {'c0_i0': -0.015321521, 'c0_i1': -0.014726171, 'c1_i0': -0.014293933, 'c1_i1': -0.013710568, 'i0_i1': 0.99992573, 'c0_c1': 0.99867386}, 59: {'c0_i0': -0.013986646, 'c0_i1': -0.013141324, 'c1_i0': -0.014258074, 'c1_i1': -0.01344333, 'i0_i1': 0.9998236, 'c0_c1': 0.9997554}, 60: {'c0_i0': -0.013139787, 'c0_i1': -0.013238704, 'c1_i0': -0.012968885, 'c1_i1': -0.013065733, 'i0_i1': 0.99991405, 'c0_c1': 0.9998523}, 61: {'c0_i0': -0.022440638, 'c0_i1': -0.02226021, 'c1_i0': -0.022276502, 'c1_i1': -0.022083335, 'i0_i1': 0.99993575, 'c0_c1': 0.99955726}, 62: {'c0_i0': -0.00315452, 'c0_i1': -0.0036952617, 'c1_i0': -0.0034284126, 'c1_i1': -0.0039694, 'i0_i1': 0.9996329, 'c0_c1': 0.9999018}, 63: {'c0_i0': -0.0042240303, 'c0_i1': -0.004389463, 'c1_i0': -0.004618246, 'c1_i1': -0.0048688827, 'i0_i1': 0.9998666, 'c0_c1': 0.99769694}, 64: {'c0_i0': -0.008952233, 'c0_i1': -0.00870019, 'c1_i0': -0.009225368, 'c1_i1': -0.008980424, 'i0_i1': 0.9998647, 'c0_c1': 0.99958324}, 65: {'c0_i0': -0.0037732916, 'c0_i1': -0.0032428019, 'c1_i0': -0.0046168407, 'c1_i1': -0.004082988, 'i0_i1': 0.99982727, 'c0_c1': 0.99966705}, 66: {'c0_i0': -0.011147663, 'c0_i1': -0.011207812, 'c1_i0': -0.011061851, 'c1_i1': -0.011122369, 'i0_i1': 0.9998806, 'c0_c1': 0.9999122}, 67: {'c0_i0': -0.004457229, 'c0_i1': -0.0044194646, 'c1_i0': -0.0044286875, 'c1_i1': -0.0043854425, 'i0_i1': 0.99959934, 'c0_c1': 0.99998736}, 68: {'c0_i0': -0.017914632, 'c0_i1': -0.01743847, 'c1_i0': -0.01851556, 'c1_i1': -0.018034553, 'i0_i1': 0.9999487, 'c0_c1': 0.99831855}, 69: {'c0_i0': -0.017373206, 'c0_i1': -0.016812459, 'c1_i0': -0.019450061, 'c1_i1': -0.018903205, 'i0_i1': 0.9998561, 'c0_c1': 0.99711615}, 70: {'c0_i0': -0.011218708, 'c0_i1': -0.011351176, 'c1_i0': -0.011138366, 'c1_i1': -0.011273057, 'i0_i1': 0.99992424, 'c0_c1': 0.9999563}, 71: {'c0_i0': -0.007972505, 'c0_i1': -0.006997343, 'c1_i0': -0.0074983705, 'c1_i1': -0.006523112, 'i0_i1': 0.9998173, 'c0_c1': 0.9998964}, 72: {'c0_i0': -0.02053215, 'c0_i1': -0.020229306, 'c1_i0': -0.017537594, 'c1_i1': -0.01727637, 'i0_i1': 0.999872, 'c0_c1': 0.9941013}, 73: {'c0_i0': -0.023358751, 'c0_i1': -0.023462031, 'c1_i0': -0.015551774, 'c1_i1': -0.015718846, 'i0_i1': 0.99988544, 'c0_c1': 0.97940767}, 74: {'c0_i0': -0.029129049, 'c0_i1': -0.02961098, 'c1_i0': -0.020109488, 'c1_i1': -0.020771533, 'i0_i1': 0.99986064, 'c0_c1': 0.98525536}, 75: {'c0_i0': -0.01682507, 'c0_i1': -0.017652284, 'c1_i0': -0.018603604, 'c1_i1': -0.019429173, 'i0_i1': 0.9998908, 'c0_c1': 0.9972485}, 76: {'c0_i0': -0.02567995, 'c0_i1': -0.02580439, 'c1_i0': -0.024334684, 'c1_i1': -0.024420792, 'i0_i1': 0.9999305, 'c0_c1': 0.99650687}, 77: {'c0_i0': -0.024018914, 'c0_i1': -0.023797583, 'c1_i0': -0.026881406, 'c1_i1': -0.026670896, 'i0_i1': 0.9999461, 'c0_c1': 0.99784833}, 78: {'c0_i0': -0.02700559, 'c0_i1': -0.026516272, 'c1_i0': -0.028704604, 'c1_i1': -0.028238935, 'i0_i1': 0.99982417, 'c0_c1': 0.9983486}, 79: {'c0_i0': -0.017614247, 'c0_i1': -0.016747724, 'c1_i0': -0.013049837, 'c1_i1': -0.012230404, 'i0_i1': 0.99870527, 'c0_c1': 0.9966554}, 80: {'c0_i0': -0.007959558, 'c0_i1': -0.008828742, 'c1_i0': -0.008920319, 'c1_i1': -0.009694614, 'i0_i1': 0.9996103, 'c0_c1': 0.99892324}, 81: {'c0_i0': -0.015569133, 'c0_i1': -0.015563909, 'c1_i0': -0.0154102715, 'c1_i1': -0.015398266, 'i0_i1': 0.99995005, 'c0_c1': 0.99989057}, 82: {'c0_i0': -0.0051793894, 'c0_i1': -0.0050017713, 'c1_i0': -0.0052791983, 'c1_i1': -0.005101802, 'i0_i1': 0.99997354, 'c0_c1': 0.9999556}, 83: {'c0_i0': -0.008817721, 'c0_i1': -0.008260898, 'c1_i0': -0.007530094, 'c1_i1': -0.006986642, 'i0_i1': 0.99927914, 'c0_c1': 0.999746}, 84: {'c0_i0': -0.007982547, 'c0_i1': -0.0079494435, 'c1_i0': -0.008452355, 'c1_i1': -0.008408749, 'i0_i1': 0.9999449, 'c0_c1': 0.9987023}, 85: {'c0_i0': -0.0147182895, 'c0_i1': -0.014358038, 'c1_i0': -0.008827258, 'c1_i1': -0.008517775, 'i0_i1': 0.9999062, 'c0_c1': 0.9969709}, 86: {'c0_i0': -0.03296385, 'c0_i1': -0.033267833, 'c1_i0': -0.03208226, 'c1_i1': -0.03239465, 'i0_i1': 0.99977684, 'c0_c1': 0.9994166}, 87: {'c0_i0': -0.018056974, 'c0_i1': -0.018800706, 'c1_i0': -0.02265653, 'c1_i1': -0.0233202, 'i0_i1': 0.9994638, 'c0_c1': 0.99643105}, 88: {'c0_i0': -0.018372416, 'c0_i1': -0.018441575, 'c1_i0': -0.0136188455, 'c1_i1': -0.013616702, 'i0_i1': 0.99993324, 'c0_c1': 0.9888337}, 89: {'c0_i0': -0.005666298, 'c0_i1': -0.0060427915, 'c1_i0': -0.00623504, 'c1_i1': -0.0066614123, 'i0_i1': 0.99989444, 'c0_c1': 0.99800026}, 90: {'c0_i0': -0.015159245, 'c0_i1': -0.014465612, 'c1_i0': -0.012860218, 'c1_i1': -0.012193905, 'i0_i1': 0.9994441, 'c0_c1': 0.9959378}, 91: {'c0_i0': -0.019007724, 'c0_i1': -0.019319113, 'c1_i0': -0.019296225, 'c1_i1': -0.01947891, 'i0_i1': 0.99979544, 'c0_c1': 0.98717266}, 92: {'c0_i0': -0.030298067, 'c0_i1': -0.03032977, 'c1_i0': -0.030305332, 'c1_i1': -0.030346967, 'i0_i1': 0.9998517, 'c0_c1': 0.99967223}, 93: {'c0_i0': -0.010804742, 'c0_i1': -0.0115088625, 'c1_i0': -0.0136061795, 'c1_i1': -0.0142502505, 'i0_i1': 0.9994155, 'c0_c1': 0.9976529}, 94: {'c0_i0': -0.0038160635, 'c0_i1': -0.005063395, 'c1_i0': -0.0068204626, 'c1_i1': -0.008148119, 'i0_i1': 0.99957705, 'c0_c1': 0.9943126}, 95: {'c0_i0': -0.031918146, 'c0_i1': -0.032213695, 'c1_i0': -0.026152685, 'c1_i1': -0.026438458, 'i0_i1': 0.99985194, 'c0_c1': 0.9911289}, 96: {'c0_i0': -0.014867995, 'c0_i1': -0.014855377, 'c1_i0': -0.018253729, 'c1_i1': -0.01835239, 'i0_i1': 0.9998694, 'c0_c1': 0.98249084}, 97: {'c0_i0': -0.008951051, 'c0_i1': -0.008826517, 'c1_i0': -0.009094492, 'c1_i1': -0.008960409, 'i0_i1': 0.99988794, 'c0_c1': 0.9988406}, 98: {'c0_i0': -0.02167963, 'c0_i1': -0.020911664, 'c1_i0': -0.026489586, 'c1_i1': -0.025695931, 'i0_i1': 0.9999252, 'c0_c1': 0.9971462}, 99: {'c0_i0': -0.009456915, 'c0_i1': -0.008902963, 'c1_i0': -0.011980294, 'c1_i1': -0.011448089, 'i0_i1': 0.99992335, 'c0_c1': 0.9968901}, 100: {'c0_i0': -0.015403196, 'c0_i1': -0.015929759, 'c1_i0': -0.014950859, 'c1_i1': -0.015479141, 'i0_i1': 0.99993354, 'c0_c1': 0.9998289}, 101: {'c0_i0': -0.0012766048, 'c0_i1': -0.001928037, 'c1_i0': -0.0030508842, 'c1_i1': -0.0036840672, 'i0_i1': 0.9998288, 'c0_c1': 0.9985096}, 102: {'c0_i0': -0.022061057, 'c0_i1': -0.021160461, 'c1_i0': -0.015422155, 'c1_i1': -0.01445399, 'i0_i1': 0.999858, 'c0_c1': 0.9914796}, 103: {'c0_i0': -0.012454409, 'c0_i1': -0.012656537, 'c1_i0': -0.012861513, 'c1_i1': -0.013078448, 'i0_i1': 0.99977005, 'c0_c1': 0.99979883}, 104: {'c0_i0': -0.006913784, 'c0_i1': -0.006319423, 'c1_i0': -0.006774864, 'c1_i1': -0.006180307, 'i0_i1': 0.99988097, 'c0_c1': 0.9999006}, 105: {'c0_i0': -0.013277123, 'c0_i1': -0.0138339475, 'c1_i0': -0.010972351, 'c1_i1': -0.011554411, 'i0_i1': 0.9997571, 'c0_c1': 0.99913114}, 106: {'c0_i0': -0.013979966, 'c0_i1': -0.014250173, 'c1_i0': -0.014343512, 'c1_i1': -0.014602188, 'i0_i1': 0.99983066, 'c0_c1': 0.9999247}, 107: {'c0_i0': -0.015715986, 'c0_i1': -0.015254518, 'c1_i0': -0.013995146, 'c1_i1': -0.013509691, 'i0_i1': 0.99989843, 'c0_c1': 0.9990448}, 108: {'c0_i0': -0.020285439, 'c0_i1': -0.020066515, 'c1_i0': -0.01708712, 'c1_i1': -0.016807685, 'i0_i1': 0.99976194, 'c0_c1': 0.99791473}, 109: {'c0_i0': -0.007944308, 'c0_i1': -0.007332635, 'c1_i0': -0.0077356114, 'c1_i1': -0.007129032, 'i0_i1': 0.99925876, 'c0_c1': 0.9992248}, 110: {'c0_i0': -0.01582435, 'c0_i1': -0.016280355, 'c1_i0': -0.015661623, 'c1_i1': -0.01612185, 'i0_i1': 0.9995735, 'c0_c1': 0.999836}, 111: {'c0_i0': -0.004730558, 'c0_i1': -0.004088375, 'c1_i0': -0.0046378924, 'c1_i1': -0.0040016565, 'i0_i1': 0.99983984, 'c0_c1': 0.9999223}, 112: {'c0_i0': -0.02096295, 'c0_i1': -0.020593017, 'c1_i0': -0.021472413, 'c1_i1': -0.021108624, 'i0_i1': 0.9999393, 'c0_c1': 0.9998728}, 113: {'c0_i0': -0.017171785, 'c0_i1': -0.016566867, 'c1_i0': -0.021678613, 'c1_i1': -0.021130137, 'i0_i1': 0.9997912, 'c0_c1': 0.99852866}, 114: {'c0_i0': -0.018354852, 'c0_i1': -0.018708622, 'c1_i0': -0.019366026, 'c1_i1': -0.019720914, 'i0_i1': 0.99980843, 'c0_c1': 0.99982023}, 115: {'c0_i0': -0.011488276, 'c0_i1': -0.011290206, 'c1_i0': -0.011419795, 'c1_i1': -0.011234347, 'i0_i1': 0.9997231, 'c0_c1': 0.9993305}, 116: {'c0_i0': -0.016729306, 'c0_i1': -0.016642356, 'c1_i0': -0.016246684, 'c1_i1': -0.01617468, 'i0_i1': 0.99973184, 'c0_c1': 0.9997091}, 117: {'c0_i0': -0.0029053045, 'c0_i1': -0.0034904154, 'c1_i0': -0.002920365, 'c1_i1': -0.0035104752, 'i0_i1': 0.999937, 'c0_c1': 0.99996537}, 118: {'c0_i0': -0.0043914765, 'c0_i1': -0.0044529065, 'c1_i0': -0.016202617, 'c1_i1': -0.016264588, 'i0_i1': 0.999841, 'c0_c1': 0.99413127}, 119: {'c0_i0': 0.004707724, 'c0_i1': 0.004118505, 'c1_i0': 0.0045498004, 'c1_i1': 0.003956685, 'i0_i1': 0.99996316, 'c0_c1': 0.99994373}, 120: {'c0_i0': -0.0115110865, 'c0_i1': -0.010533423, 'c1_i0': -0.012092231, 'c1_i1': -0.01111383, 'i0_i1': 0.9994227, 'c0_c1': 0.9998963}, 121: {'c0_i0': -0.014792776, 'c0_i1': -0.015222505, 'c1_i0': -0.0123828165, 'c1_i1': -0.012791498, 'i0_i1': 0.999913, 'c0_c1': 0.99936116}, 122: {'c0_i0': -0.009475039, 'c0_i1': -0.009505754, 'c1_i0': -0.0067412127, 'c1_i1': -0.0067334324, 'i0_i1': 0.9998316, 'c0_c1': 0.9975673}, 123: {'c0_i0': -0.0136249205, 'c0_i1': -0.012972146, 'c1_i0': -0.012971289, 'c1_i1': -0.012315754, 'i0_i1': 0.9998443, 'c0_c1': 0.9988242}, 124: {'c0_i0': -0.022060338, 'c0_i1': -0.022116037, 'c1_i0': -0.021886706, 'c1_i1': -0.021938272, 'i0_i1': 0.9999547, 'c0_c1': 0.99947745}, 125: {'c0_i0': -0.019526176, 'c0_i1': -0.01879385, 'c1_i0': -0.020265799, 'c1_i1': -0.019440906, 'i0_i1': 0.99990976, 'c0_c1': 0.9938715}, 126: {'c0_i0': 0.0027981987, 'c0_i1': 0.0023386115, 'c1_i0': 0.0026810234, 'c1_i1': 0.0022259671, 'i0_i1': 0.9997644, 'c0_c1': 0.99993193}, 127: {'c0_i0': -0.013641963, 'c0_i1': -0.011564573, 'c1_i0': -0.013626192, 'c1_i1': -0.011565109, 'i0_i1': 0.9996701, 'c0_c1': 0.9998011}, 128: {'c0_i0': -0.011125805, 'c0_i1': -0.010844549, 'c1_i0': -0.010811958, 'c1_i1': -0.010540444, 'i0_i1': 0.99993664, 'c0_c1': 0.999827}, 129: {'c0_i0': -0.017482953, 'c0_i1': -0.01739385, 'c1_i0': -0.0174398, 'c1_i1': -0.017346535, 'i0_i1': 0.99992096, 'c0_c1': 0.9995423}, 130: {'c0_i0': -0.0015498269, 'c0_i1': -0.0019130474, 'c1_i0': -0.0023502717, 'c1_i1': -0.0027132211, 'i0_i1': 0.9998425, 'c0_c1': 0.99978644}, 131: {'c0_i0': -0.010178591, 'c0_i1': -0.012308224, 'c1_i0': -0.012257889, 'c1_i1': -0.013895452, 'i0_i1': 0.9990071, 'c0_c1': 0.98501086}, 132: {'c0_i0': -0.017360121, 'c0_i1': -0.016891234, 'c1_i0': -0.017755603, 'c1_i1': -0.017425846, 'i0_i1': 0.9998358, 'c0_c1': 0.99754643}, 133: {'c0_i0': -0.016065056, 'c0_i1': -0.016022397, 'c1_i0': -0.018651094, 'c1_i1': -0.018702984, 'i0_i1': 0.9997864, 'c0_c1': 0.99765605}, 134: {'c0_i0': -0.02591765, 'c0_i1': -0.026615944, 'c1_i0': -0.026212167, 'c1_i1': -0.02694753, 'i0_i1': 0.9995673, 'c0_c1': 0.9984982}, 135: {'c0_i0': -0.012204807, 'c0_i1': -0.01147435, 'c1_i0': -0.0117270425, 'c1_i1': -0.011001838, 'i0_i1': 0.99994975, 'c0_c1': 0.9994891}, 136: {'c0_i0': -0.008937445, 'c0_i1': -0.008389955, 'c1_i0': -0.013953008, 'c1_i1': -0.01343583, 'i0_i1': 0.9998816, 'c0_c1': 0.99785763}, 137: {'c0_i0': -0.016795807, 'c0_i1': -0.016486838, 'c1_i0': -0.017459717, 'c1_i1': -0.017151885, 'i0_i1': 0.99992186, 'c0_c1': 0.9998257}, 138: {'c0_i0': -0.013254901, 'c0_i1': -0.012267374, 'c1_i0': -0.012150761, 'c1_i1': -0.011166889, 'i0_i1': 0.9999016, 'c0_c1': 0.99987906}, 139: {'c0_i0': -0.025736162, 'c0_i1': -0.026488397, 'c1_i0': -0.026236504, 'c1_i1': -0.02696977, 'i0_i1': 0.99976236, 'c0_c1': 0.9999155}, 140: {'c0_i0': -0.009685512, 'c0_i1': -0.009778695, 'c1_i0': -0.011314556, 'c1_i1': -0.0114144655, 'i0_i1': 0.99989265, 'c0_c1': 0.9985319}, 141: {'c0_i0': -0.00973923, 'c0_i1': -0.009556659, 'c1_i0': -0.010214937, 'c1_i1': -0.010078859, 'i0_i1': 0.99992764, 'c0_c1': 0.99860966}, 142: {'c0_i0': -0.013619004, 'c0_i1': -0.013449076, 'c1_i0': -0.014650947, 'c1_i1': -0.014488495, 'i0_i1': 0.9995339, 'c0_c1': 0.9997731}, 143: {'c0_i0': -0.008265833, 'c0_i1': -0.008690394, 'c1_i0': -0.0076336022, 'c1_i1': -0.008055076, 'i0_i1': 0.999951, 'c0_c1': 0.9981646}, 144: {'c0_i0': -0.0068704523, 'c0_i1': -0.0068485606, 'c1_i0': -0.008237032, 'c1_i1': -0.008179729, 'i0_i1': 0.999812, 'c0_c1': 0.99851614}, 145: {'c0_i0': -0.008597389, 'c0_i1': -0.009182888, 'c1_i0': -0.008989975, 'c1_i1': -0.009573495, 'i0_i1': 0.9999094, 'c0_c1': 0.99989337}, 146: {'c0_i0': -0.015485216, 'c0_i1': -0.015764823, 'c1_i0': -0.015252022, 'c1_i1': -0.015491589, 'i0_i1': 0.99953175, 'c0_c1': 0.9996986}, 147: {'c0_i0': -0.008386239, 'c0_i1': -0.008560397, 'c1_i0': -0.008445414, 'c1_i1': -0.008602389, 'i0_i1': 0.99990594, 'c0_c1': 0.9996454}, 148: {'c0_i0': -0.025641492, 'c0_i1': -0.02615475, 'c1_i0': -0.015921598, 'c1_i1': -0.016447425, 'i0_i1': 0.9999229, 'c0_c1': 0.98085064}, 149: {'c0_i0': -0.025790121, 'c0_i1': -0.025863243, 'c1_i0': -0.022328844, 'c1_i1': -0.022384994, 'i0_i1': 0.999913, 'c0_c1': 0.99314094}, 150: {'c0_i0': -0.012226125, 'c0_i1': -0.011302284, 'c1_i0': -0.01630106, 'c1_i1': -0.0152834505, 'i0_i1': 0.99969316, 'c0_c1': 0.98744965}, 151: {'c0_i0': -0.01464379, 'c0_i1': -0.014425191, 'c1_i0': -0.014075284, 'c1_i1': -0.013880845, 'i0_i1': 0.99984384, 'c0_c1': 0.99252605}, 152: {'c0_i0': -0.020719556, 'c0_i1': -0.020967443, 'c1_i0': -0.022149842, 'c1_i1': -0.022429813, 'i0_i1': 0.9999559, 'c0_c1': 0.9872068}, 153: {'c0_i0': -0.022021111, 'c0_i1': -0.022799512, 'c1_i0': -0.019262064, 'c1_i1': -0.020134538, 'i0_i1': 0.999697, 'c0_c1': 0.99239993}, 154: {'c0_i0': -0.017453158, 'c0_i1': -0.018275946, 'c1_i0': -0.019094843, 'c1_i1': -0.019968608, 'i0_i1': 0.9998833, 'c0_c1': 0.99894637}, 155: {'c0_i0': -0.01017879, 'c0_i1': -0.010210743, 'c1_i0': -0.0075668376, 'c1_i1': -0.0076366477, 'i0_i1': 0.999677, 'c0_c1': 0.99541306}, 156: {'c0_i0': -0.019965086, 'c0_i1': -0.019818336, 'c1_i0': -0.021704752, 'c1_i1': -0.021590205, 'i0_i1': 0.99980074, 'c0_c1': 0.9993921}, 157: {'c0_i0': -0.007592596, 'c0_i1': -0.008396873, 'c1_i0': -0.009844324, 'c1_i1': -0.010624817, 'i0_i1': 0.99975526, 'c0_c1': 0.9987898}, 158: {'c0_i0': -0.024679855, 'c0_i1': -0.02548685, 'c1_i0': -0.02548961, 'c1_i1': -0.026333213, 'i0_i1': 0.99985355, 'c0_c1': 0.99956983}, 159: {'c0_i0': -0.015962895, 'c0_i1': -0.016620765, 'c1_i0': -0.008109979, 'c1_i1': -0.008723141, 'i0_i1': 0.9999002, 'c0_c1': 0.9979857}, 160: {'c0_i0': -0.00869797, 'c0_i1': -0.00807566, 'c1_i0': -0.009595614, 'c1_i1': -0.008971984, 'i0_i1': 0.9996207, 'c0_c1': 0.9991266}, 161: {'c0_i0': -0.017989445, 'c0_i1': -0.017677974, 'c1_i0': -0.017084641, 'c1_i1': -0.016783899, 'i0_i1': 0.99967474, 'c0_c1': 0.99922127}, 162: {'c0_i0': -0.014905989, 'c0_i1': -0.014933314, 'c1_i0': -0.017895626, 'c1_i1': -0.017795997, 'i0_i1': 0.9990134, 'c0_c1': 0.9939406}, 163: {'c0_i0': -0.0061191125, 'c0_i1': -0.0061305314, 'c1_i0': -0.0127622215, 'c1_i1': -0.01287552, 'i0_i1': 0.99988395, 'c0_c1': 0.99317586}, 164: {'c0_i0': -0.02353878, 'c0_i1': -0.023853278, 'c1_i0': -0.01733038, 'c1_i1': -0.017617594, 'i0_i1': 0.99945235, 'c0_c1': 0.98239404}, 165: {'c0_i0': -0.023145303, 'c0_i1': -0.022973932, 'c1_i0': -0.0250456, 'c1_i1': -0.024919458, 'i0_i1': 0.99976754, 'c0_c1': 0.9970456}, 166: {'c0_i0': -0.02306619, 'c0_i1': -0.022595681, 'c1_i0': -0.022617381, 'c1_i1': -0.022142548, 'i0_i1': 0.9999293, 'c0_c1': 0.9989612}, 167: {'c0_i0': -0.02088102, 'c0_i1': -0.020282194, 'c1_i0': -0.020503359, 'c1_i1': -0.019922966, 'i0_i1': 0.99980634, 'c0_c1': 0.9992349}, 168: {'c0_i0': -0.013601784, 'c0_i1': -0.013975583, 'c1_i0': -0.013736308, 'c1_i1': -0.014106813, 'i0_i1': 0.99987245, 'c0_c1': 0.9987521}, 169: {'c0_i0': -0.017900275, 'c0_i1': -0.018497601, 'c1_i0': -0.014581036, 'c1_i1': -0.015219858, 'i0_i1': 0.9996666, 'c0_c1': 0.9981368}, 170: {'c0_i0': -0.009176853, 'c0_i1': -0.009987193, 'c1_i0': -0.0075188973, 'c1_i1': -0.008330121, 'i0_i1': 0.99972576, 'c0_c1': 0.9985141}, 171: {'c0_i0': -0.022346986, 'c0_i1': -0.021889927, 'c1_i0': -0.016758572, 'c1_i1': -0.01626704, 'i0_i1': 0.9998726, 'c0_c1': 0.997709}, 172: {'c0_i0': -0.015866661, 'c0_i1': -0.016393771, 'c1_i0': -0.015133164, 'c1_i1': -0.01561835, 'i0_i1': 0.999795, 'c0_c1': 0.99897826}, 173: {'c0_i0': -0.01672961, 'c0_i1': -0.016648958, 'c1_i0': -0.019635644, 'c1_i1': -0.019514687, 'i0_i1': 0.9998782, 'c0_c1': 0.99681425}, 174: {'c0_i0': -0.01787806, 'c0_i1': -0.018361151, 'c1_i0': -0.01541579, 'c1_i1': -0.015996398, 'i0_i1': 0.9997582, 'c0_c1': 0.99440855}, 175: {'c0_i0': -0.031033829, 'c0_i1': -0.030623479, 'c1_i0': -0.0298431, 'c1_i1': -0.02937562, 'i0_i1': 0.9998895, 'c0_c1': 0.9965465}, 176: {'c0_i0': -0.014845491, 'c0_i1': -0.015027547, 'c1_i0': -0.013513042, 'c1_i1': -0.0137340585, 'i0_i1': 0.99990666, 'c0_c1': 0.9974515}, 177: {'c0_i0': -0.026890984, 'c0_i1': -0.02722862, 'c1_i0': -0.03108016, 'c1_i1': -0.031372435, 'i0_i1': 0.99993014, 'c0_c1': 0.9954484}, 178: {'c0_i0': -0.018647186, 'c0_i1': -0.018940287, 'c1_i0': -0.020386964, 'c1_i1': -0.020675842, 'i0_i1': 0.9999397, 'c0_c1': 0.9989141}, 179: {'c0_i0': -0.019998124, 'c0_i1': -0.020358715, 'c1_i0': -0.018049235, 'c1_i1': -0.018460033, 'i0_i1': 0.9997273, 'c0_c1': 0.9990666}, 180: {'c0_i0': -0.028064694, 'c0_i1': -0.027993355, 'c1_i0': -0.030430041, 'c1_i1': -0.030413372, 'i0_i1': 0.99986684, 'c0_c1': 0.99822617}, 181: {'c0_i0': -0.0025292952, 'c0_i1': -0.002695987, 'c1_i0': -0.0023785736, 'c1_i1': -0.002544907, 'i0_i1': 0.9999682, 'c0_c1': 0.9999708}, 182: {'c0_i0': -0.015589599, 'c0_i1': -0.016309677, 'c1_i0': -0.015528476, 'c1_i1': -0.01624569, 'i0_i1': 0.9999192, 'c0_c1': 0.99997455}, 183: {'c0_i0': 0.00019084476, 'c0_i1': 0.0005402025, 'c1_i0': 8.877367e-06, 'c1_i1': 0.00036248006, 'i0_i1': 0.9999076, 'c0_c1': 0.9999482}, 184: {'c0_i0': -0.006791063, 'c0_i1': -0.006368954, 'c1_i0': -0.006943331, 'c1_i1': -0.006525449, 'i0_i1': 0.9995995, 'c0_c1': 0.99990535}, 185: {'c0_i0': -0.007897694, 'c0_i1': -0.0077578304, 'c1_i0': -0.007495404, 'c1_i1': -0.0073592137, 'i0_i1': 0.9998888, 'c0_c1': 0.9999038}, 186: {'c0_i0': -0.0022323513, 'c0_i1': -0.0025756005, 'c1_i0': -0.0020268261, 'c1_i1': -0.0023697056, 'i0_i1': 0.99967694, 'c0_c1': 0.9999658}, 187: {'c0_i0': -0.0103698615, 'c0_i1': -0.011180536, 'c1_i0': -0.011616619, 'c1_i1': -0.012408335, 'i0_i1': 0.9997173, 'c0_c1': 0.9998373}, 188: {'c0_i0': -0.008662336, 'c0_i1': -0.008912234, 'c1_i0': -0.009275304, 'c1_i1': -0.009526264, 'i0_i1': 0.9999143, 'c0_c1': 0.99966294}, 189: {'c0_i0': -0.0068187118, 'c0_i1': -0.006923997, 'c1_i0': -0.008289427, 'c1_i1': -0.008383862, 'i0_i1': 0.99991834, 'c0_c1': 0.99887806}, 190: {'c0_i0': -0.009990355, 'c0_i1': -0.009760593, 'c1_i0': -0.010581599, 'c1_i1': -0.010341196, 'i0_i1': 0.99990416, 'c0_c1': 0.99980253}, 191: {'c0_i0': -0.02426304, 'c0_i1': -0.02345128, 'c1_i0': -0.017914832, 'c1_i1': -0.017107483, 'i0_i1': 0.99967134, 'c0_c1': 0.9978765}, 192: {'c0_i0': -0.018244997, 'c0_i1': -0.018220779, 'c1_i0': -0.018767623, 'c1_i1': -0.01874368, 'i0_i1': 0.9999337, 'c0_c1': 0.9996898}, 193: {'c0_i0': -0.023568857, 'c0_i1': -0.023278536, 'c1_i0': -0.024558, 'c1_i1': -0.02427211, 'i0_i1': 0.9999152, 'c0_c1': 0.99981326}, 194: {'c0_i0': -0.0050222594, 'c0_i1': -0.0042919014, 'c1_i0': -0.0056604473, 'c1_i1': -0.00493019, 'i0_i1': 0.9997441, 'c0_c1': 0.99968797}, 195: {'c0_i0': -0.01478016, 'c0_i1': -0.014538122, 'c1_i0': -0.016063489, 'c1_i1': -0.015821984, 'i0_i1': 0.9999492, 'c0_c1': 0.99954224}, 196: {'c0_i0': -0.016564466, 'c0_i1': -0.01696531, 'c1_i0': -0.014733879, 'c1_i1': -0.015144786, 'i0_i1': 0.9997879, 'c0_c1': 0.99940073}, 197: {'c0_i0': -0.012991967, 'c0_i1': -0.012731279, 'c1_i0': -0.013099696, 'c1_i1': -0.0128466245, 'i0_i1': 0.9996942, 'c0_c1': 0.99986625}, 198: {'c0_i0': -0.021093098, 'c0_i1': -0.021880958, 'c1_i0': -0.022102447, 'c1_i1': -0.022899233, 'i0_i1': 0.9998353, 'c0_c1': 0.99804026}, 199: {'c0_i0': -0.011552272, 'c0_i1': -0.011071287, 'c1_i0': -0.011290114, 'c1_i1': -0.01082154, 'i0_i1': 0.9999517, 'c0_c1': 0.99938554}, 200: {'c0_i0': -0.01270761, 'c0_i1': -0.013114523, 'c1_i0': -0.013398168, 'c1_i1': -0.013813997, 'i0_i1': 0.999004, 'c0_c1': 0.999864}, 201: {'c0_i0': -0.0060397713, 'c0_i1': -0.0061297677, 'c1_i0': -0.006573933, 'c1_i1': -0.0066676177, 'i0_i1': 0.99995124, 'c0_c1': 0.99981886}, 202: {'c0_i0': -0.032073066, 'c0_i1': -0.032792717, 'c1_i0': -0.03337784, 'c1_i1': -0.034103572, 'i0_i1': 0.9995034, 'c0_c1': 0.9986245}, 203: {'c0_i0': 0.0022275327, 'c0_i1': 0.0016630748, 'c1_i0': 0.0011770539, 'c1_i1': 0.0006142948, 'i0_i1': 0.99985325, 'c0_c1': 0.9998553}, 204: {'c0_i0': -0.025666974, 'c0_i1': -0.02602035, 'c1_i0': -0.025291096, 'c1_i1': -0.025691532, 'i0_i1': 0.9998058, 'c0_c1': 0.99373263}, 205: {'c0_i0': -0.0153446505, 'c0_i1': -0.015584341, 'c1_i0': -0.017526038, 'c1_i1': -0.01779239, 'i0_i1': 0.9999705, 'c0_c1': 0.9967689}, 206: {'c0_i0': -0.0027784957, 'c0_i1': -0.0021627275, 'c1_i0': -0.0013071764, 'c1_i1': -0.0006787861, 'i0_i1': 0.9998009, 'c0_c1': 0.99977505}, 207: {'c0_i0': -0.029679086, 'c0_i1': -0.029423827, 'c1_i0': -0.030463621, 'c1_i1': -0.03024001, 'i0_i1': 0.9998839, 'c0_c1': 0.99950165}, 208: {'c0_i0': -0.009348087, 'c0_i1': -0.009625245, 'c1_i0': -0.0091187935, 'c1_i1': -0.009429779, 'i0_i1': 0.99947405, 'c0_c1': 0.99860066}, 209: {'c0_i0': -0.0012528673, 'c0_i1': 0.00046422705, 'c1_i0': -0.00211911, 'c1_i1': -0.00026426744, 'i0_i1': 0.9982845, 'c0_c1': 0.99870217}, 210: {'c0_i0': -0.011694444, 'c0_i1': -0.010979325, 'c1_i0': -0.013105452, 'c1_i1': -0.012394693, 'i0_i1': 0.9997859, 'c0_c1': 0.9995072}, 211: {'c0_i0': -0.0083311675, 'c0_i1': -0.007595607, 'c1_i0': -0.0075857583, 'c1_i1': -0.006842762, 'i0_i1': 0.9997743, 'c0_c1': 0.9995254}, 212: {'c0_i0': -0.012514077, 'c0_i1': -0.013647452, 'c1_i0': -0.0141221965, 'c1_i1': -0.015189432, 'i0_i1': 0.9994018, 'c0_c1': 0.9992877}, 213: {'c0_i0': -0.0069151926, 'c0_i1': -0.0072725476, 'c1_i0': -0.0060049174, 'c1_i1': -0.0063543757, 'i0_i1': 0.99996185, 'c0_c1': 0.99887383}, 214: {'c0_i0': -0.016358647, 'c0_i1': -0.016316822, 'c1_i0': -0.01636545, 'c1_i1': -0.016362017, 'i0_i1': 0.9994668, 'c0_c1': 0.99868435}, 215: {'c0_i0': -0.013846576, 'c0_i1': -0.014826379, 'c1_i0': -0.014165299, 'c1_i1': -0.015147146, 'i0_i1': 0.9994917, 'c0_c1': 0.9999746}, 216: {'c0_i0': -0.021688547, 'c0_i1': -0.021894656, 'c1_i0': -0.022187836, 'c1_i1': -0.022573713, 'i0_i1': 0.9998414, 'c0_c1': 0.992779}, 217: {'c0_i0': -0.012060272, 'c0_i1': -0.012124643, 'c1_i0': -0.012819488, 'c1_i1': -0.012892596, 'i0_i1': 0.99996436, 'c0_c1': 0.9976665}, 218: {'c0_i0': -0.007186799, 'c0_i1': -0.0064051356, 'c1_i0': -0.006641566, 'c1_i1': -0.005879318, 'i0_i1': 0.9994504, 'c0_c1': 0.9998864}, 219: {'c0_i0': -0.016545571, 'c0_i1': -0.017314129, 'c1_i0': -0.017100943, 'c1_i1': -0.017897923, 'i0_i1': 0.9995737, 'c0_c1': 0.9999116}, 220: {'c0_i0': -0.013636226, 'c0_i1': -0.012980245, 'c1_i0': -0.010065657, 'c1_i1': -0.009359265, 'i0_i1': 0.99982846, 'c0_c1': 0.9975165}, 221: {'c0_i0': -0.013165505, 'c0_i1': -0.013458075, 'c1_i0': -0.008358937, 'c1_i1': -0.008654311, 'i0_i1': 0.9998395, 'c0_c1': 0.99196017}, 222: {'c0_i0': -0.0071746856, 'c0_i1': -0.006467811, 'c1_i0': -0.010655438, 'c1_i1': -0.009914406, 'i0_i1': 0.9998758, 'c0_c1': 0.99614596}, 223: {'c0_i0': -0.007116507, 'c0_i1': -0.005937477, 'c1_i0': -0.00542262, 'c1_i1': -0.0042496505, 'i0_i1': 0.99911547, 'c0_c1': 0.9994575}, 224: {'c0_i0': -0.02464926, 'c0_i1': -0.024902225, 'c1_i0': -0.023497146, 'c1_i1': -0.023741912, 'i0_i1': 0.99993694, 'c0_c1': 0.9910864}, 225: {'c0_i0': -0.019329559, 'c0_i1': -0.019509189, 'c1_i0': -0.019878399, 'c1_i1': -0.020074848, 'i0_i1': 0.99982506, 'c0_c1': 0.9998625}, 226: {'c0_i0': -0.009980357, 'c0_i1': -0.010175457, 'c1_i0': -0.010267597, 'c1_i1': -0.01048124, 'i0_i1': 0.9999413, 'c0_c1': 0.9996527}, 227: {'c0_i0': -0.0125469435, 'c0_i1': -0.012786476, 'c1_i0': -0.008323478, 'c1_i1': -0.00855539, 'i0_i1': 0.9998801, 'c0_c1': 0.99676466}, 228: {'c0_i0': -0.02288313, 'c0_i1': -0.023013439, 'c1_i0': -0.022531731, 'c1_i1': -0.022676371, 'i0_i1': 0.9996489, 'c0_c1': 0.999142}, 229: {'c0_i0': -0.014075918, 'c0_i1': -0.013556572, 'c1_i0': -0.01342713, 'c1_i1': -0.012894227, 'i0_i1': 0.99982834, 'c0_c1': 0.99738204}, 230: {'c0_i0': -0.015599683, 'c0_i1': -0.015518518, 'c1_i0': -0.0147769265, 'c1_i1': -0.014682801, 'i0_i1': 0.99989545, 'c0_c1': 0.99971163}, 231: {'c0_i0': -0.010800561, 'c0_i1': -0.010551379, 'c1_i0': -0.012210479, 'c1_i1': -0.011956131, 'i0_i1': 0.99996245, 'c0_c1': 0.9996791}, 232: {'c0_i0': -0.007901832, 'c0_i1': -0.009564697, 'c1_i0': -0.0076449616, 'c1_i1': -0.0093081845, 'i0_i1': 0.99925846, 'c0_c1': 0.99988776}, 233: {'c0_i0': -0.01990303, 'c0_i1': -0.018859677, 'c1_i0': -0.016208278, 'c1_i1': -0.015189045, 'i0_i1': 0.9998642, 'c0_c1': 0.9973967}, 234: {'c0_i0': -0.017625172, 'c0_i1': -0.016639337, 'c1_i0': -0.017686673, 'c1_i1': -0.016756183, 'i0_i1': 0.99990904, 'c0_c1': 0.99842244}, 235: {'c0_i0': -0.016347531, 'c0_i1': -0.016384939, 'c1_i0': -0.0057293046, 'c1_i1': -0.005815631, 'i0_i1': 0.99991745, 'c0_c1': 0.9944731}, 236: {'c0_i0': -0.008018613, 'c0_i1': -0.008231291, 'c1_i0': -0.0066300575, 'c1_i1': -0.006861803, 'i0_i1': 0.99997747, 'c0_c1': 0.9975893}, 237: {'c0_i0': -0.030418403, 'c0_i1': -0.030204924, 'c1_i0': -0.0147065865, 'c1_i1': -0.014369718, 'i0_i1': 0.9999399, 'c0_c1': 0.974086}, 238: {'c0_i0': -0.0058957604, 'c0_i1': -0.006030852, 'c1_i0': -0.005399879, 'c1_i1': -0.0055453223, 'i0_i1': 0.9999057, 'c0_c1': 0.99967796}, 239: {'c0_i0': -0.0031229686, 'c0_i1': -0.0039643804, 'c1_i0': -0.0030696783, 'c1_i1': -0.0038888138, 'i0_i1': 0.99953246, 'c0_c1': 0.99990624}, 240: {'c0_i0': -0.016601093, 'c0_i1': -0.016647015, 'c1_i0': -0.01604843, 'c1_i1': -0.016108949, 'i0_i1': 0.9999248, 'c0_c1': 0.99920845}, 241: {'c0_i0': -0.016464584, 'c0_i1': -0.016507288, 'c1_i0': -0.015560707, 'c1_i1': -0.015593906, 'i0_i1': 0.9999502, 'c0_c1': 0.9994998}, 242: {'c0_i0': 0.0003376389, 'c0_i1': -9.285752e-05, 'c1_i0': 0.0011645863, 'c1_i1': 0.00073627476, 'i0_i1': 0.99938154, 'c0_c1': 0.9998815}, 243: {'c0_i0': -0.0035698954, 'c0_i1': -0.0045711584, 'c1_i0': -0.0029757032, 'c1_i1': -0.003975681, 'i0_i1': 0.99975324, 'c0_c1': 0.99976844}, 244: {'c0_i0': -0.0013808617, 'c0_i1': -0.0011596791, 'c1_i0': -0.0017742319, 'c1_i1': -0.0015276829, 'i0_i1': 0.9996707, 'c0_c1': 0.9998442}, 245: {'c0_i0': -0.0061362684, 'c0_i1': -0.006147608, 'c1_i0': -0.0074204057, 'c1_i1': -0.007405768, 'i0_i1': 0.9999206, 'c0_c1': 0.98942596}, 246: {'c0_i0': -0.016371887, 'c0_i1': -0.016871952, 'c1_i0': -0.018674709, 'c1_i1': -0.019107174, 'i0_i1': 0.99976087, 'c0_c1': 0.9915324}, 247: {'c0_i0': -0.016518623, 'c0_i1': -0.016467372, 'c1_i0': -0.018471505, 'c1_i1': -0.018398698, 'i0_i1': 0.99993956, 'c0_c1': 0.9882548}, 248: {'c0_i0': -0.007106458, 'c0_i1': -0.0064251935, 'c1_i0': -0.006608594, 'c1_i1': -0.0059292335, 'i0_i1': 0.9997904, 'c0_c1': 0.99997073}, 249: {'c0_i0': -0.013109863, 'c0_i1': -0.013204248, 'c1_i0': -0.013269664, 'c1_i1': -0.0133516295, 'i0_i1': 0.99989355, 'c0_c1': 0.9996389}, 250: {'c0_i0': -0.012807207, 'c0_i1': -0.012316994, 'c1_i0': -0.013889552, 'c1_i1': -0.013434623, 'i0_i1': 0.9998503, 'c0_c1': 0.99946404}, 251: {'c0_i0': -0.012234232, 'c0_i1': -0.012385331, 'c1_i0': -0.015135085, 'c1_i1': -0.0152384015, 'i0_i1': 0.99987257, 'c0_c1': 0.99639386}, 252: {'c0_i0': -0.008153513, 'c0_i1': -0.00840789, 'c1_i0': -0.008625181, 'c1_i1': -0.008888269, 'i0_i1': 0.99989444, 'c0_c1': 0.9998286}, 253: {'c0_i0': -0.018154532, 'c0_i1': -0.01724406, 'c1_i0': -0.0185522, 'c1_i1': -0.017660525, 'i0_i1': 0.99952817, 'c0_c1': 0.999913}, 254: {'c0_i0': -0.00010888465, 'c0_i1': -0.0002768878, 'c1_i0': -0.0019800141, 'c1_i1': -0.0022254372, 'i0_i1': 0.99952936, 'c0_c1': 0.9987387}, 255: {'c0_i0': -0.009377324, 'c0_i1': -0.009296846, 'c1_i0': -0.010002317, 'c1_i1': -0.009926263, 'i0_i1': 0.99990785, 'c0_c1': 0.9997347}, 256: {'c0_i0': -0.009717177, 'c0_i1': -0.008987751, 'c1_i0': -0.010257179, 'c1_i1': -0.009531646, 'i0_i1': 0.9998578, 'c0_c1': 0.9990217}, 257: {'c0_i0': -0.025575088, 'c0_i1': -0.024929885, 'c1_i0': -0.026683927, 'c1_i1': -0.02593328, 'i0_i1': 0.99954134, 'c0_c1': 0.99614555}, 258: {'c0_i0': -0.008827632, 'c0_i1': -0.008864811, 'c1_i0': -0.0065021487, 'c1_i1': -0.00651953, 'i0_i1': 0.99979734, 'c0_c1': 0.9991025}, 259: {'c0_i0': -0.018909488, 'c0_i1': -0.01867334, 'c1_i0': -0.018627215, 'c1_i1': -0.018391488, 'i0_i1': 0.99988556, 'c0_c1': 0.99993396}, 260: {'c0_i0': -0.0142324865, 'c0_i1': -0.013434066, 'c1_i0': -0.013171294, 'c1_i1': -0.012365751, 'i0_i1': 0.99975765, 'c0_c1': 0.9995057}, 261: {'c0_i0': -0.014530255, 'c0_i1': -0.015356891, 'c1_i0': -0.015635522, 'c1_i1': -0.016465504, 'i0_i1': 0.99974805, 'c0_c1': 0.9997973}, 262: {'c0_i0': -0.014124654, 'c0_i1': -0.014434412, 'c1_i0': -0.01515831, 'c1_i1': -0.015472347, 'i0_i1': 0.99992555, 'c0_c1': 0.99576867}, 263: {'c0_i0': -0.02569052, 'c0_i1': -0.025663419, 'c1_i0': -0.023138175, 'c1_i1': -0.022938382, 'i0_i1': 0.99965274, 'c0_c1': 0.9832284}, 264: {'c0_i0': -0.012024602, 'c0_i1': -0.012433191, 'c1_i0': -0.011566551, 'c1_i1': -0.011973836, 'i0_i1': 0.99984515, 'c0_c1': 0.99982345}, 265: {'c0_i0': -0.015142323, 'c0_i1': -0.0149024995, 'c1_i0': -0.016023789, 'c1_i1': -0.015793275, 'i0_i1': 0.9998449, 'c0_c1': 0.9987936}, 266: {'c0_i0': -0.0008213632, 'c0_i1': -0.0013096742, 'c1_i0': -0.00024138577, 'c1_i1': -0.00073298067, 'i0_i1': 0.9999494, 'c0_c1': 0.9999486}, 267: {'c0_i0': 0.0017000763, 'c0_i1': 0.0012401445, 'c1_i0': 0.0010881424, 'c1_i1': 0.0006394349, 'i0_i1': 0.9996501, 'c0_c1': 0.9997953}, 268: {'c0_i0': -0.012197347, 'c0_i1': -0.012248179, 'c1_i0': -0.011989585, 'c1_i1': -0.01202479, 'i0_i1': 0.99990153, 'c0_c1': 0.99988407}, 269: {'c0_i0': -0.0025890972, 'c0_i1': -0.0020157313, 'c1_i0': -0.00480495, 'c1_i1': -0.0042772912, 'i0_i1': 0.99954605, 'c0_c1': 0.9990766}, 270: {'c0_i0': -0.0058984216, 'c0_i1': -0.006358088, 'c1_i0': -0.006732939, 'c1_i1': -0.007150394, 'i0_i1': 0.9996773, 'c0_c1': 0.99952525}, 271: {'c0_i0': -0.0044090897, 'c0_i1': -0.0046441313, 'c1_i0': -0.0029200856, 'c1_i1': -0.0031447494, 'i0_i1': 0.99983877, 'c0_c1': 0.9988854}, 272: {'c0_i0': -0.021676818, 'c0_i1': -0.02159324, 'c1_i0': -0.021033257, 'c1_i1': -0.020941164, 'i0_i1': 0.99965125, 'c0_c1': 0.9997338}, 273: {'c0_i0': -0.011326527, 'c0_i1': -0.011030199, 'c1_i0': -0.010755583, 'c1_i1': -0.010457208, 'i0_i1': 0.9996796, 'c0_c1': 0.9994755}, 274: {'c0_i0': -0.018188553, 'c0_i1': -0.018308517, 'c1_i0': -0.019491699, 'c1_i1': -0.019641113, 'i0_i1': 0.99995255, 'c0_c1': 0.98843884}, 275: {'c0_i0': -0.013216975, 'c0_i1': -0.0129882805, 'c1_i0': -0.0072622346, 'c1_i1': -0.007112316, 'i0_i1': 0.9999422, 'c0_c1': 0.991127}, 276: {'c0_i0': -0.009512184, 'c0_i1': -0.008995546, 'c1_i0': -0.009866552, 'c1_i1': -0.0093338955, 'i0_i1': 0.99983084, 'c0_c1': 0.9995909}, 277: {'c0_i0': -0.0065278267, 'c0_i1': -0.006172118, 'c1_i0': -0.006702934, 'c1_i1': -0.0063526197, 'i0_i1': 0.99993825, 'c0_c1': 0.9997634}, 278: {'c0_i0': -0.011032449, 'c0_i1': -0.011627697, 'c1_i0': -0.011767305, 'c1_i1': -0.012363605, 'i0_i1': 0.9994264, 'c0_c1': 0.9993251}, 279: {'c0_i0': -0.0038993089, 'c0_i1': -0.004442877, 'c1_i0': -0.004835655, 'c1_i1': -0.0053795427, 'i0_i1': 0.9999182, 'c0_c1': 0.9996466}, 280: {'c0_i0': -0.013160058, 'c0_i1': -0.0137462765, 'c1_i0': -0.012838559, 'c1_i1': -0.013400756, 'i0_i1': 0.9996805, 'c0_c1': 0.9997696}, 281: {'c0_i0': -0.027698388, 'c0_i1': -0.027488692, 'c1_i0': -0.025957888, 'c1_i1': -0.025748346, 'i0_i1': 0.999905, 'c0_c1': 0.9973479}, 282: {'c0_i0': -0.013883954, 'c0_i1': -0.013743302, 'c1_i0': -0.013276522, 'c1_i1': -0.013158982, 'i0_i1': 0.99980927, 'c0_c1': 0.99960095}, 283: {'c0_i0': -0.01062583, 'c0_i1': -0.0101024555, 'c1_i0': -0.017413, 'c1_i1': -0.01692959, 'i0_i1': 0.99990857, 'c0_c1': 0.99177825}, 284: {'c0_i0': -0.003918688, 'c0_i1': -0.0037830593, 'c1_i0': -0.0038543167, 'c1_i1': -0.003705061, 'i0_i1': 0.99976146, 'c0_c1': 0.9998542}, 285: {'c0_i0': -0.008643558, 'c0_i1': -0.0081836535, 'c1_i0': -0.009587767, 'c1_i1': -0.008990603, 'i0_i1': 0.99905485, 'c0_c1': 0.998645}, 286: {'c0_i0': -0.0023418898, 'c0_i1': -0.0029056007, 'c1_i0': -0.00081144273, 'c1_i1': -0.0013760235, 'i0_i1': 0.9999193, 'c0_c1': 0.99951786}, 287: {'c0_i0': -0.012540746, 'c0_i1': -0.01319672, 'c1_i0': -0.012128749, 'c1_i1': -0.012812357, 'i0_i1': 0.999545, 'c0_c1': 0.99991506}, 288: {'c0_i0': -0.006200932, 'c0_i1': -0.0064850384, 'c1_i0': -0.005963215, 'c1_i1': -0.0062589366, 'i0_i1': 0.99985534, 'c0_c1': 0.9998009}, 289: {'c0_i0': 4.19626e-05, 'c0_i1': 0.0005208589, 'c1_i0': -0.0010366179, 'c1_i1': -0.00056524854, 'i0_i1': 0.9998517, 'c0_c1': 0.9993562}, 290: {'c0_i0': -0.009150993, 'c0_i1': -0.009210816, 'c1_i0': -0.00925237, 'c1_i1': -0.009300675, 'i0_i1': 0.99996555, 'c0_c1': 0.9995011}, 291: {'c0_i0': -0.012267199, 'c0_i1': -0.012054864, 'c1_i0': -0.012000237, 'c1_i1': -0.011791933, 'i0_i1': 0.99987376, 'c0_c1': 0.9999126}, 292: {'c0_i0': -0.011001245, 'c0_i1': -0.010451456, 'c1_i0': -0.01187491, 'c1_i1': -0.011316894, 'i0_i1': 0.9999087, 'c0_c1': 0.9998157}, 293: {'c0_i0': -0.017885733, 'c0_i1': -0.017226538, 'c1_i0': -0.017179005, 'c1_i1': -0.016579352, 'i0_i1': 0.9998832, 'c0_c1': 0.9981471}, 294: {'c0_i0': -0.0043666093, 'c0_i1': -0.004392149, 'c1_i0': -0.0038148183, 'c1_i1': -0.003829835, 'i0_i1': 0.9999525, 'c0_c1': 0.99970293}, 295: {'c0_i0': -0.0008442532, 'c0_i1': -0.0014107171, 'c1_i0': -0.0013536792, 'c1_i1': -0.0019208193, 'i0_i1': 0.9998778, 'c0_c1': 0.999883}, 296: {'c0_i0': -0.0043398365, 'c0_i1': -0.0044367537, 'c1_i0': -0.0049243094, 'c1_i1': -0.0050299577, 'i0_i1': 0.99992883, 'c0_c1': 0.9999136}, 297: {'c0_i0': -0.0033164266, 'c0_i1': -0.0034182873, 'c1_i0': -0.0027749995, 'c1_i1': -0.0028729606, 'i0_i1': 0.9994083, 'c0_c1': 0.9999331}, 298: {'c0_i0': -0.0063602533, 'c0_i1': -0.005035593, 'c1_i0': -0.006789698, 'c1_i1': -0.005449039, 'i0_i1': 0.9993844, 'c0_c1': 0.9997829}, 299: {'c0_i0': -0.013697473, 'c0_i1': -0.013141166, 'c1_i0': -0.01276923, 'c1_i1': -0.012212617, 'i0_i1': 0.9997992, 'c0_c1': 0.9999036}, 300: {'c0_i0': -0.011775949, 'c0_i1': -0.011873949, 'c1_i0': -0.0107426, 'c1_i1': -0.010830934, 'i0_i1': 0.9998981, 'c0_c1': 0.9984142}, 301: {'c0_i0': -0.018571304, 'c0_i1': -0.018428467, 'c1_i0': -0.012236519, 'c1_i1': -0.01215997, 'i0_i1': 0.99989355, 'c0_c1': 0.9970982}, 302: {'c0_i0': -0.01339763, 'c0_i1': -0.014057127, 'c1_i0': -0.014790635, 'c1_i1': -0.015356396, 'i0_i1': 0.99955714, 'c0_c1': 0.99785554}, 303: {'c0_i0': -0.014018039, 'c0_i1': -0.014702051, 'c1_i0': -0.012721749, 'c1_i1': -0.013379488, 'i0_i1': 0.99922115, 'c0_c1': 0.9996892}, 304: {'c0_i0': -0.019618344, 'c0_i1': -0.01945927, 'c1_i0': -0.02005022, 'c1_i1': -0.019902084, 'i0_i1': 0.9998175, 'c0_c1': 0.9998671}, 305: {'c0_i0': -0.025018625, 'c0_i1': -0.024897043, 'c1_i0': -0.022737082, 'c1_i1': -0.022637052, 'i0_i1': 0.9999268, 'c0_c1': 0.99556744}, 306: {'c0_i0': -0.020833574, 'c0_i1': -0.020126408, 'c1_i0': -0.022566125, 'c1_i1': -0.021858506, 'i0_i1': 0.9997965, 'c0_c1': 0.99836105}, 307: {'c0_i0': -0.009002016, 'c0_i1': -0.009186633, 'c1_i0': -0.010299431, 'c1_i1': -0.010448753, 'i0_i1': 0.9997586, 'c0_c1': 0.9970658}, 308: {'c0_i0': -0.0120949885, 'c0_i1': -0.012644894, 'c1_i0': -0.010746468, 'c1_i1': -0.011290211, 'i0_i1': 0.99983037, 'c0_c1': 0.99988085}, 309: {'c0_i0': -0.011995874, 'c0_i1': -0.012181984, 'c1_i0': -0.012519285, 'c1_i1': -0.012718774, 'i0_i1': 0.9999279, 'c0_c1': 0.9990432}, 310: {'c0_i0': -0.005544409, 'c0_i1': -0.0049779806, 'c1_i0': -0.009151697, 'c1_i1': -0.008598197, 'i0_i1': 0.9998124, 'c0_c1': 0.998025}, 311: {'c0_i0': -0.0019965926, 'c0_i1': -0.0016667722, 'c1_i0': -0.0017677797, 'c1_i1': -0.0014406135, 'i0_i1': 0.9998009, 'c0_c1': 0.99986374}, 312: {'c0_i0': -0.014021875, 'c0_i1': -0.014399948, 'c1_i0': -0.013379157, 'c1_i1': -0.013750382, 'i0_i1': 0.9999707, 'c0_c1': 0.9997212}, 313: {'c0_i0': -0.0036224565, 'c0_i1': -0.003282221, 'c1_i0': -0.0035856534, 'c1_i1': -0.0032523815, 'i0_i1': 0.99988097, 'c0_c1': 0.99893713}, 314: {'c0_i0': -0.0060270494, 'c0_i1': -0.006457515, 'c1_i0': -0.0052924035, 'c1_i1': -0.005714002, 'i0_i1': 0.99993634, 'c0_c1': 0.9997034}, 315: {'c0_i0': -0.0062397327, 'c0_i1': -0.006000039, 'c1_i0': -0.0043594437, 'c1_i1': -0.0041439654, 'i0_i1': 0.99992585, 'c0_c1': 0.997667}, 316: {'c0_i0': -0.022233691, 'c0_i1': -0.022343175, 'c1_i0': -0.023177367, 'c1_i1': -0.023286432, 'i0_i1': 0.9999568, 'c0_c1': 0.9990341}, 317: {'c0_i0': -0.021977864, 'c0_i1': -0.022790004, 'c1_i0': -0.018539326, 'c1_i1': -0.019466262, 'i0_i1': 0.9995351, 'c0_c1': 0.99758637}, 318: {'c0_i0': -0.01912332, 'c0_i1': -0.019286143, 'c1_i0': -0.015617795, 'c1_i1': -0.01586877, 'i0_i1': 0.9998621, 'c0_c1': 0.9928926}, 319: {'c0_i0': -0.010795161, 'c0_i1': -0.0106637515, 'c1_i0': -0.010501287, 'c1_i1': -0.0104740495, 'i0_i1': 0.9996438, 'c0_c1': 0.99573386}, 320: {'c0_i0': -0.0125984, 'c0_i1': -0.012209708, 'c1_i0': -0.0048185093, 'c1_i1': -0.0044796597, 'i0_i1': 0.9990591, 'c0_c1': 0.99557716}, 321: {'c0_i0': -0.021654043, 'c0_i1': -0.021652395, 'c1_i0': -0.025818454, 'c1_i1': -0.025790617, 'i0_i1': 0.99994457, 'c0_c1': 0.99175775}, 322: {'c0_i0': -0.025660831, 'c0_i1': -0.02544012, 'c1_i0': -0.026767952, 'c1_i1': -0.026591506, 'i0_i1': 0.9998722, 'c0_c1': 0.99242866}, 323: {'c0_i0': -0.017842509, 'c0_i1': -0.018077428, 'c1_i0': -0.020428373, 'c1_i1': -0.020667063, 'i0_i1': 0.9999111, 'c0_c1': 0.9881722}, 324: {'c0_i0': -0.017169248, 'c0_i1': -0.017543897, 'c1_i0': -0.010455031, 'c1_i1': -0.010743926, 'i0_i1': 0.9998803, 'c0_c1': 0.98723847}, 325: {'c0_i0': -0.024106845, 'c0_i1': -0.02339241, 'c1_i0': -0.024405742, 'c1_i1': -0.023665553, 'i0_i1': 0.9998074, 'c0_c1': 0.99676204}, 326: {'c0_i0': 0.0020529684, 'c0_i1': 0.0014906749, 'c1_i0': -0.00019858684, 'c1_i1': -0.00084001943, 'i0_i1': 0.99988544, 'c0_c1': 0.9961445}, 327: {'c0_i0': -0.027770285, 'c0_i1': -0.029263414, 'c1_i0': -0.025496246, 'c1_i1': -0.026942078, 'i0_i1': 0.9994862, 'c0_c1': 0.97940993}, 328: {'c0_i0': -0.006358238, 'c0_i1': -0.007612966, 'c1_i0': -0.0077508017, 'c1_i1': -0.009024098, 'i0_i1': 0.99970686, 'c0_c1': 0.9992504}, 329: {'c0_i0': -0.01991254, 'c0_i1': -0.019969556, 'c1_i0': -0.020272909, 'c1_i1': -0.020327492, 'i0_i1': 0.99997175, 'c0_c1': 0.9997624}, 330: {'c0_i0': -0.0097866785, 'c0_i1': -0.0101469895, 'c1_i0': -0.01048716, 'c1_i1': -0.0108523425, 'i0_i1': 0.99973226, 'c0_c1': 0.99983615}, 331: {'c0_i0': -0.01226607, 'c0_i1': -0.012158012, 'c1_i0': -0.012070874, 'c1_i1': -0.011928618, 'i0_i1': 0.99989194, 'c0_c1': 0.9984509}, 332: {'c0_i0': -0.020394478, 'c0_i1': -0.01981131, 'c1_i0': -0.02203476, 'c1_i1': -0.021466658, 'i0_i1': 0.9998667, 'c0_c1': 0.9994184}, 333: {'c0_i0': -0.013640658, 'c0_i1': -0.015102278, 'c1_i0': -0.012720417, 'c1_i1': -0.01403045, 'i0_i1': 0.9996221, 'c0_c1': 0.98216164}, 334: {'c0_i0': -0.016363602, 'c0_i1': -0.016638182, 'c1_i0': -0.012992155, 'c1_i1': -0.0133077465, 'i0_i1': 0.99989074, 'c0_c1': 0.9922609}, 335: {'c0_i0': -0.016361382, 'c0_i1': -0.016527876, 'c1_i0': -0.016298784, 'c1_i1': -0.016465995, 'i0_i1': 0.9999722, 'c0_c1': 0.9999852}, 336: {'c0_i0': -0.018916417, 'c0_i1': -0.019453613, 'c1_i0': -0.018953513, 'c1_i1': -0.019490711, 'i0_i1': 0.9995669, 'c0_c1': 0.9999864}, 337: {'c0_i0': -0.0125803, 'c0_i1': -0.012723143, 'c1_i0': -0.013176622, 'c1_i1': -0.013342835, 'i0_i1': 0.9998001, 'c0_c1': 0.9967899}, 338: {'c0_i0': -0.015861236, 'c0_i1': -0.015786525, 'c1_i0': -0.012627344, 'c1_i1': -0.012574684, 'i0_i1': 0.99998814, 'c0_c1': 0.99716944}, 339: {'c0_i0': -0.02200572, 'c0_i1': -0.022660496, 'c1_i0': -0.022675565, 'c1_i1': -0.023388274, 'i0_i1': 0.9997839, 'c0_c1': 0.99645746}, 340: {'c0_i0': -0.009495634, 'c0_i1': -0.009165962, 'c1_i0': -0.0109975375, 'c1_i1': -0.010684202, 'i0_i1': 0.9999276, 'c0_c1': 0.99840134}, 341: {'c0_i0': -0.009434266, 'c0_i1': -0.010163702, 'c1_i0': -0.009757965, 'c1_i1': -0.010476952, 'i0_i1': 0.99968314, 'c0_c1': 0.99982846}, 342: {'c0_i0': 0.0037949514, 'c0_i1': 0.0038966145, 'c1_i0': -0.0006241612, 'c1_i1': -0.0004743971, 'i0_i1': 0.9998776, 'c0_c1': 0.9934752}, 343: {'c0_i0': -0.035176862, 'c0_i1': -0.035231292, 'c1_i0': -0.032735102, 'c1_i1': -0.03276668, 'i0_i1': 0.9998797, 'c0_c1': 0.9926111}, 344: {'c0_i0': -0.02081566, 'c0_i1': -0.020823577, 'c1_i0': -0.019540634, 'c1_i1': -0.019552555, 'i0_i1': 0.99999446, 'c0_c1': 0.9997639}, 345: {'c0_i0': -0.01233975, 'c0_i1': -0.013148141, 'c1_i0': -0.013793565, 'c1_i1': -0.014659023, 'i0_i1': 0.99968964, 'c0_c1': 0.99807644}, 346: {'c0_i0': -0.01108399, 'c0_i1': -0.0114023425, 'c1_i0': -0.010927223, 'c1_i1': -0.011228699, 'i0_i1': 0.9998687, 'c0_c1': 0.99760735}, 347: {'c0_i0': -0.014805503, 'c0_i1': -0.014127415, 'c1_i0': -0.01472532, 'c1_i1': -0.0140461475, 'i0_i1': 0.999956, 'c0_c1': 0.99990165}, 348: {'c0_i0': -0.027914949, 'c0_i1': -0.027694266, 'c1_i0': -0.028340142, 'c1_i1': -0.028131764, 'i0_i1': 0.99963343, 'c0_c1': 0.9984524}, 349: {'c0_i0': -0.01910321, 'c0_i1': -0.019420894, 'c1_i0': -0.017641366, 'c1_i1': -0.017969936, 'i0_i1': 0.999963, 'c0_c1': 0.9989328}, 350: {'c0_i0': -0.008256841, 'c0_i1': -0.008151449, 'c1_i0': -0.015595806, 'c1_i1': -0.015438367, 'i0_i1': 0.9999666, 'c0_c1': 0.9942759}, 351: {'c0_i0': -0.013144961, 'c0_i1': -0.013831416, 'c1_i0': -0.006923247, 'c1_i1': -0.0075915456, 'i0_i1': 0.99989307, 'c0_c1': 0.9950304}, 352: {'c0_i0': -0.0051514087, 'c0_i1': -0.004869938, 'c1_i0': -0.012400891, 'c1_i1': -0.01216807, 'i0_i1': 0.99983025, 'c0_c1': 0.99682343}, 353: {'c0_i0': -0.019790556, 'c0_i1': -0.019269833, 'c1_i0': -0.02004098, 'c1_i1': -0.019495137, 'i0_i1': 0.9989479, 'c0_c1': 0.99734485}, 354: {'c0_i0': -0.01941133, 'c0_i1': -0.019728115, 'c1_i0': -0.019610524, 'c1_i1': -0.019922132, 'i0_i1': 0.9996412, 'c0_c1': 0.9989062}, 355: {'c0_i0': -0.020855252, 'c0_i1': -0.020692412, 'c1_i0': -0.019618833, 'c1_i1': -0.019466897, 'i0_i1': 0.99992585, 'c0_c1': 0.99894166}, 356: {'c0_i0': -0.014250822, 'c0_i1': -0.014135734, 'c1_i0': -0.013819023, 'c1_i1': -0.01369594, 'i0_i1': 0.9997748, 'c0_c1': 0.9991963}, 357: {'c0_i0': -0.0076806126, 'c0_i1': -0.007653872, 'c1_i0': -0.006944581, 'c1_i1': -0.006926422, 'i0_i1': 0.999928, 'c0_c1': 0.9996695}, 358: {'c0_i0': -0.013719631, 'c0_i1': -0.012870237, 'c1_i0': -0.013057996, 'c1_i1': -0.012213266, 'i0_i1': 0.99988997, 'c0_c1': 0.9999625}, 359: {'c0_i0': -0.018591255, 'c0_i1': -0.01840339, 'c1_i0': -0.018845137, 'c1_i1': -0.018663557, 'i0_i1': 0.9999368, 'c0_c1': 0.9996521}, 360: {'c0_i0': -0.014117744, 'c0_i1': -0.013524443, 'c1_i0': -0.013035366, 'c1_i1': -0.012420462, 'i0_i1': 0.99996006, 'c0_c1': 0.999099}, 361: {'c0_i0': -0.010757408, 'c0_i1': -0.010279497, 'c1_i0': -0.0110723665, 'c1_i1': -0.010579469, 'i0_i1': 0.99972117, 'c0_c1': 0.99994594}, 362: {'c0_i0': -0.03041927, 'c0_i1': -0.030937646, 'c1_i0': -0.029512344, 'c1_i1': -0.029998742, 'i0_i1': 0.9998707, 'c0_c1': 0.9991325}, 363: {'c0_i0': -0.034424245, 'c0_i1': -0.035066824, 'c1_i0': -0.035437405, 'c1_i1': -0.03611274, 'i0_i1': 0.9998737, 'c0_c1': 0.9988066}, 364: {'c0_i0': -0.036725335, 'c0_i1': -0.037257798, 'c1_i0': -0.027728802, 'c1_i1': -0.028429937, 'i0_i1': 0.9997965, 'c0_c1': 0.9883615}, 365: {'c0_i0': -0.012471756, 'c0_i1': -0.012716321, 'c1_i0': -0.016003823, 'c1_i1': -0.016261071, 'i0_i1': 0.9998293, 'c0_c1': 0.9915135}, 366: {'c0_i0': -0.021181118, 'c0_i1': -0.021000475, 'c1_i0': -0.016843518, 'c1_i1': -0.016647045, 'i0_i1': 0.9999262, 'c0_c1': 0.99539655}, 367: {'c0_i0': -0.008012253, 'c0_i1': -0.00816528, 'c1_i0': -0.011139704, 'c1_i1': -0.011299026, 'i0_i1': 0.99995005, 'c0_c1': 0.99832964}, 368: {'c0_i0': -0.015643008, 'c0_i1': -0.0163222, 'c1_i0': -0.012033055, 'c1_i1': -0.0127071105, 'i0_i1': 0.9998783, 'c0_c1': 0.99828744}, 369: {'c0_i0': -0.019207302, 'c0_i1': -0.019355237, 'c1_i0': -0.02065769, 'c1_i1': -0.02079289, 'i0_i1': 0.99996215, 'c0_c1': 0.99880415}, 370: {'c0_i0': -0.011098634, 'c0_i1': -0.010510655, 'c1_i0': -0.011815324, 'c1_i1': -0.011291578, 'i0_i1': 0.99969435, 'c0_c1': 0.99538386}, 371: {'c0_i0': -0.003475939, 'c0_i1': -0.0037102345, 'c1_i0': -0.004432638, 'c1_i1': -0.004670593, 'i0_i1': 0.9998764, 'c0_c1': 0.99679995}, 372: {'c0_i0': -0.016292082, 'c0_i1': -0.016142324, 'c1_i0': -0.019764671, 'c1_i1': -0.019602567, 'i0_i1': 0.99954504, 'c0_c1': 0.9987554}, 373: {'c0_i0': -0.020959415, 'c0_i1': -0.02128544, 'c1_i0': -0.019757587, 'c1_i1': -0.020071903, 'i0_i1': 0.99991757, 'c0_c1': 0.9971655}, 374: {'c0_i0': -0.015821602, 'c0_i1': -0.015210916, 'c1_i0': -0.017296007, 'c1_i1': -0.016686365, 'i0_i1': 0.9999032, 'c0_c1': 0.9991454}, 375: {'c0_i0': -0.008899524, 'c0_i1': -0.007618974, 'c1_i0': -0.006823737, 'c1_i1': -0.005437076, 'i0_i1': 0.9997339, 'c0_c1': 0.9882134}, 376: {'c0_i0': -0.021448163, 'c0_i1': -0.021216296, 'c1_i0': -0.022943912, 'c1_i1': -0.022768691, 'i0_i1': 0.9999629, 'c0_c1': 0.99719155}, 377: {'c0_i0': -0.016267054, 'c0_i1': -0.01658539, 'c1_i0': -0.016209159, 'c1_i1': -0.016551504, 'i0_i1': 0.99985075, 'c0_c1': 0.99884415}, 378: {'c0_i0': -0.016787801, 'c0_i1': -0.017090596, 'c1_i0': -0.015658032, 'c1_i1': -0.0160053, 'i0_i1': 0.9999099, 'c0_c1': 0.99808186}, 379: {'c0_i0': -0.009411395, 'c0_i1': -0.009787255, 'c1_i0': -0.010210849, 'c1_i1': -0.010650228, 'i0_i1': 0.9999231, 'c0_c1': 0.99644685}, 380: {'c0_i0': -0.024881938, 'c0_i1': -0.024997283, 'c1_i0': -0.024575079, 'c1_i1': -0.024714949, 'i0_i1': 0.9998264, 'c0_c1': 0.99940944}, 381: {'c0_i0': -0.010351991, 'c0_i1': -0.010865776, 'c1_i0': -0.01630189, 'c1_i1': -0.016832642, 'i0_i1': 0.9998846, 'c0_c1': 0.9845171}, 382: {'c0_i0': -0.01516121, 'c0_i1': -0.014768829, 'c1_i0': -0.0137716625, 'c1_i1': -0.013362163, 'i0_i1': 0.9997282, 'c0_c1': 0.9995903}, 383: {'c0_i0': -0.0029175244, 'c0_i1': -0.003049804, 'c1_i0': -0.0014908817, 'c1_i1': -0.0016490202, 'i0_i1': 0.999396, 'c0_c1': 0.9988978}, 384: {'c0_i0': -0.008543875, 'c0_i1': -0.008400702, 'c1_i0': -0.009968025, 'c1_i1': -0.009824219, 'i0_i1': 0.99979275, 'c0_c1': 0.9970498}, 385: {'c0_i0': -0.021726375, 'c0_i1': -0.022663755, 'c1_i0': -0.02232701, 'c1_i1': -0.02326035, 'i0_i1': 0.9992831, 'c0_c1': 0.99940616}, 386: {'c0_i0': -0.022384588, 'c0_i1': -0.022510946, 'c1_i0': -0.015947498, 'c1_i1': -0.016080778, 'i0_i1': 0.99995637, 'c0_c1': 0.99173975}, 387: {'c0_i0': -0.003688613, 'c0_i1': -0.003474407, 'c1_i0': -0.0049056355, 'c1_i1': -0.004680236, 'i0_i1': 0.99992204, 'c0_c1': 0.99913216}, 388: {'c0_i0': -0.015597791, 'c0_i1': -0.015357405, 'c1_i0': -0.015414117, 'c1_i1': -0.015200991, 'i0_i1': 0.9996389, 'c0_c1': 0.9993297}, 389: {'c0_i0': -0.014896011, 'c0_i1': -0.015015867, 'c1_i0': -0.01167011, 'c1_i1': -0.0118034305, 'i0_i1': 0.99996585, 'c0_c1': 0.99453497}, 390: {'c0_i0': -0.017344063, 'c0_i1': -0.016225498, 'c1_i0': -0.019971495, 'c1_i1': -0.01889533, 'i0_i1': 0.99944067, 'c0_c1': 0.99563825}, 391: {'c0_i0': -0.008939822, 'c0_i1': -0.009266909, 'c1_i0': -0.0088483635, 'c1_i1': -0.009195932, 'i0_i1': 0.99980915, 'c0_c1': 0.99962384}, 392: {'c0_i0': -0.017144568, 'c0_i1': -0.016660294, 'c1_i0': -0.017759142, 'c1_i1': -0.01727864, 'i0_i1': 0.9998815, 'c0_c1': 0.9996725}, 393: {'c0_i0': -0.021016682, 'c0_i1': -0.020982672, 'c1_i0': -0.014615006, 'c1_i1': -0.014579161, 'i0_i1': 0.99989235, 'c0_c1': 0.98211277}, 394: {'c0_i0': -0.008667366, 'c0_i1': -0.009038462, 'c1_i0': -0.0029010568, 'c1_i1': -0.00332582, 'i0_i1': 0.9999193, 'c0_c1': 0.99029595}, 395: {'c0_i0': -0.013553659, 'c0_i1': -0.012911863, 'c1_i0': -0.014306943, 'c1_i1': -0.013632041, 'i0_i1': 0.99981284, 'c0_c1': 0.99815226}, 396: {'c0_i0': -0.00024887826, 'c0_i1': -0.0011933679, 'c1_i0': -0.0023298888, 'c1_i1': -0.0032639932, 'i0_i1': 0.99976146, 'c0_c1': 0.99958956}, 397: {'c0_i0': -0.004158523, 'c0_i1': -0.0039712293, 'c1_i0': -0.0021559848, 'c1_i1': -0.0019788835, 'i0_i1': 0.9999631, 'c0_c1': 0.99933875}, 398: {'c0_i0': -0.03435743, 'c0_i1': -0.034532715, 'c1_i0': -0.029897407, 'c1_i1': -0.030035991, 'i0_i1': 0.9998704, 'c0_c1': 0.99544275}, 399: {'c0_i0': -0.017026031, 'c0_i1': -0.017081676, 'c1_i0': -0.019913854, 'c1_i1': -0.020051487, 'i0_i1': 0.99984616, 'c0_c1': 0.9896114}}\n"
     ]
    }
   ],
   "source": [
    "print(winoground_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "winoground_str = {}\n",
    "for key in winoground_scores:\n",
    "  winoground_str[key] = {}\n",
    "  for x in winoground_scores[key]:\n",
    "    winoground_str[key][x] = str(f'{winoground_scores[key][x]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"winoground_scores-4to8.json\", 'w') as f:\n",
    "  json.dump(winoground_str, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text score: 0.0\n",
      "image score: 0.0125\n",
      "group score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Scoring\n",
    "text_correct_count = 0\n",
    "image_correct_count = 0\n",
    "group_correct_count = 0\n",
    "\n",
    "for result in winoground_scores.values():\n",
    "    text_correct_count += 1 if text_correct(result) else 0\n",
    "    image_correct_count += 1 if image_correct(result) else 0\n",
    "    group_correct_count += 1 if group_correct(result) else 0\n",
    "\n",
    "denominator = len(winoground_scores)\n",
    "print(\"text score:\", text_correct_count/denominator)\n",
    "print(\"image score:\", image_correct_count/denominator)\n",
    "print(\"group score:\", group_correct_count/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
